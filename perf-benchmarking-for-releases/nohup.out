+ '[' 2 -gt 2 ']'
+ BENCHMARK_COUNT=1
+ GCSFUSE_VERSION=enable_read_manager_flag
+ RERUN=true
+ rm -rf /tmp/update_benchmarks.1eDdWo
++ mktemp -d -t update_benchmarks.XXXXXX
+ TMP_DIR=/tmp/update_benchmarks.YILFOC
+ [[ true == \f\a\l\s\e ]]
+ echo 'Logging in: /tmp/update_benchmarks.YILFOC/enable_read_manager_flag-c4'
Logging in: /tmp/update_benchmarks.YILFOC/enable_read_manager_flag-c4
+ echo 'Logging in: /tmp/update_benchmarks.YILFOC/enable_read_manager_flag-n2'
Logging in: /tmp/update_benchmarks.YILFOC/enable_read_manager_flag-n2
+ [[ true == \t\r\u\e ]]
+ benchmark_pids=()
+ benchmark_pids+=($!)
+ ./run-benchmarks.sh enable_read_manager_flag gcs-fuse-test us-south1 n2-standard-96 ubuntu-2204-lts ubuntu-os-cloud 1
+ benchmark_pids+=($!)
+ for pid in "${benchmark_pids[@]}"
+ wait 2939182
+ ./run-benchmarks.sh enable_read_manager_flag gcs-fuse-test us-south1 c4-standard-96 ubuntu-2204-lts ubuntu-os-cloud 1
+ for pid in "${benchmark_pids[@]}"
+ wait 2939183
+ ./create_benchmark_tables.sh enable_read_manager_flag us-south1 c4-standard-96 'gVNIC+ tier_1 networking (200Gbps)' 'Hyperdisk balanced' 1
+ '[' 6 -ne 6 ']'
++ mktemp -d -t create_benchmark_tables.XXXXXX
+ TMP_DIR=/tmp/create_benchmark_tables.dKkjUd
+ trap 'rm -rf "$TMP_DIR"' EXIT
+ TABLES_FILE=/tmp/create_benchmark_tables.dKkjUd/tables.md
+ RESULTS_BUCKET_NAME=gcsfuse-release-benchmarks-results
+ GCSFUSE_VERSION=enable_read_manager_flag
+ REGION=us-south1
+ MACHINE_TYPE=c4-standard-96
+ NETWORKING='gVNIC+ tier_1 networking (200Gbps)'
+ DISK_TYPE='Hyperdisk balanced'
+ BENCHMARK_COUNT=1
+ RANDOM_READ_RES_BASENAME=gcsfuse-random-read-workload-benchmark
+ SEQ_READ_RES_BASENAME=gcsfuse-sequential-read-workload-benchmark
+ WRITE_RES_BASENAME=gcsfuse-write-workload-benchmark
+ JSON_FILES_BASENAMES=("$RANDOM_READ_RES_BASENAME" "$SEQ_READ_RES_BASENAME" "$WRITE_RES_BASENAME")
+ gcloud storage objects describe gs://gcsfuse-release-benchmarks-results/enable_read_manager_flag/c4-standard-96/success.txt
+ echo 'Found the success.txt file in the bucket.'
Found the success.txt file in the bucket.
+ for basename in "${JSON_FILES_BASENAMES[@]}"
++ seq 1 1
+ for i in $(seq 1 "$BENCHMARK_COUNT")
+ curr_filename=gcsfuse-random-read-workload-benchmark_1.json
+ gcloud storage cp gs://gcsfuse-release-benchmarks-results/enable_read_manager_flag/c4-standard-96/gcsfuse-random-read-workload-benchmark_1.json /tmp/create_benchmark_tables.dKkjUd/gcsfuse-random-read-workload-benchmark_1.json
Copying gs://gcsfuse-release-benchmarks-results/enable_read_manager_flag/c4-standard-96/gcsfuse-random-read-workload-benchmark_1.json to file:///tmp/create_benchmark_tables.dKkjUd/gcsfuse-random-read-workload-benchmark_1.json
  
..
+ sed -i '/^note:/d' /tmp/create_benchmark_tables.dKkjUd/gcsfuse-random-read-workload-benchmark_1.json
+ for basename in "${JSON_FILES_BASENAMES[@]}"
++ seq 1 1
+ for i in $(seq 1 "$BENCHMARK_COUNT")
+ curr_filename=gcsfuse-sequential-read-workload-benchmark_1.json
+ gcloud storage cp gs://gcsfuse-release-benchmarks-results/enable_read_manager_flag/c4-standard-96/gcsfuse-sequential-read-workload-benchmark_1.json /tmp/create_benchmark_tables.dKkjUd/gcsfuse-sequential-read-workload-benchmark_1.json
Copying gs://gcsfuse-release-benchmarks-results/enable_read_manager_flag/c4-standard-96/gcsfuse-sequential-read-workload-benchmark_1.json to file:///tmp/create_benchmark_tables.dKkjUd/gcsfuse-sequential-read-workload-benchmark_1.json
  
..
+ sed -i '/^note:/d' /tmp/create_benchmark_tables.dKkjUd/gcsfuse-sequential-read-workload-benchmark_1.json
+ for basename in "${JSON_FILES_BASENAMES[@]}"
++ seq 1 1
+ for i in $(seq 1 "$BENCHMARK_COUNT")
+ curr_filename=gcsfuse-write-workload-benchmark_1.json
+ gcloud storage cp gs://gcsfuse-release-benchmarks-results/enable_read_manager_flag/c4-standard-96/gcsfuse-write-workload-benchmark_1.json /tmp/create_benchmark_tables.dKkjUd/gcsfuse-write-workload-benchmark_1.json
Copying gs://gcsfuse-release-benchmarks-results/enable_read_manager_flag/c4-standard-96/gcsfuse-write-workload-benchmark_1.json to file:///tmp/create_benchmark_tables.dKkjUd/gcsfuse-write-workload-benchmark_1.json
  
...
+ sed -i '/^note:/d' /tmp/create_benchmark_tables.dKkjUd/gcsfuse-write-workload-benchmark_1.json
+ RANDOM_READ_RES=/tmp/create_benchmark_tables.dKkjUd/gcsfuse-random-read-workload-benchmark
+ SEQ_READ_RES=/tmp/create_benchmark_tables.dKkjUd/gcsfuse-sequential-read-workload-benchmark
+ WRITE_RES=/tmp/create_benchmark_tables.dKkjUd/gcsfuse-write-workload-benchmark
+ ROW_COUNT=0
+ declare -a filesize bw_bytes nrfiles iops lat_mean bs
+ bytes_in=(['MB']='1000000' ['GB']='1000000000')
+ declare -A bytes_in
+ create_tables_markdown_content
+ echo '## GCSFuse Benchmarking on c4 machine-type'
+ echo '* VM Type: c4-standard-96'
+ echo '* VM location: us-south1'
+ echo '* Networking: gVNIC+ tier_1 networking (200Gbps)'
+ echo '* Disk Type: Hyperdisk balanced'
+ echo '* GCS Bucket location: us-south1'
+ echo ''
+ create_table 'Sequential Reads' /tmp/create_benchmark_tables.dKkjUd/gcsfuse-sequential-read-workload-benchmark read GB
+ local 'table_name=Sequential Reads'
+ local file=/tmp/create_benchmark_tables.dKkjUd/gcsfuse-sequential-read-workload-benchmark
+ local workflow_type=read
+ local bw_in=GB
+ echo '### Sequential Reads'
++ job_count /tmp/create_benchmark_tables.dKkjUd/gcsfuse-sequential-read-workload-benchmark_1.json
++ local file=/tmp/create_benchmark_tables.dKkjUd/gcsfuse-sequential-read-workload-benchmark_1.json
++ local count
+++ jq '.jobs | length' /tmp/create_benchmark_tables.dKkjUd/gcsfuse-sequential-read-workload-benchmark_1.json
++ count=9
++ [[ 9 -le 0 ]]
++ echo 9
+ ROW_COUNT=9
+ populate_all_columns /tmp/create_benchmark_tables.dKkjUd/gcsfuse-sequential-read-workload-benchmark read
+ local file=/tmp/create_benchmark_tables.dKkjUd/gcsfuse-sequential-read-workload-benchmark
+ local op_type=read
+ local lat_ns_op_type=read.lat_ns
+ populate_array_from_jq /tmp/create_benchmark_tables.dKkjUd/gcsfuse-sequential-read-workload-benchmark_1.json '.jobs[]?."job options"' '."global options"' bs bs
+ local file=/tmp/create_benchmark_tables.dKkjUd/gcsfuse-sequential-read-workload-benchmark_1.json
+ local 'jq_job_path_template=.jobs[]?."job options"'
+ local 'jq_global_path_template=."global options"'
+ local field_name=bs
+ local -n array_ref=bs
+ array_ref=()
+ local 'jq_job_query=.jobs[]?."job options"["bs"]?'
+ local 'jq_global_query=."global options"["bs"]?'
+ mapfile -t values
++ jq -r '.jobs[]?."job options"["bs"]?' /tmp/create_benchmark_tables.dKkjUd/gcsfuse-sequential-read-workload-benchmark_1.json
+ local i
+ for i in "${!values[@]}"
+ local value=128K
+ [[ 128K == \n\u\l\l ]]
+ [[ 128K == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=128K
+ [[ 128K == \n\u\l\l ]]
+ [[ 128K == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=1M
+ [[ 1M == \n\u\l\l ]]
+ [[ 1M == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=1M
+ [[ 1M == \n\u\l\l ]]
+ [[ 1M == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=1M
+ [[ 1M == \n\u\l\l ]]
+ [[ 1M == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=1M
+ [[ 1M == \n\u\l\l ]]
+ [[ 1M == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=1M
+ [[ 1M == \n\u\l\l ]]
+ [[ 1M == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=1M
+ [[ 1M == \n\u\l\l ]]
+ [[ 1M == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=1M
+ [[ 1M == \n\u\l\l ]]
+ [[ 1M == \n\u\l\l ]]
+ array_ref+=("$value")
+ [[ 9 -ne 9 ]]
+ populate_array_from_jq /tmp/create_benchmark_tables.dKkjUd/gcsfuse-sequential-read-workload-benchmark_1.json '.jobs[]?."job options"' '."global options"' filesize filesize
+ local file=/tmp/create_benchmark_tables.dKkjUd/gcsfuse-sequential-read-workload-benchmark_1.json
+ local 'jq_job_path_template=.jobs[]?."job options"'
+ local 'jq_global_path_template=."global options"'
+ local field_name=filesize
+ local -n array_ref=filesize
+ array_ref=()
+ local 'jq_job_query=.jobs[]?."job options"["filesize"]?'
+ local 'jq_global_query=."global options"["filesize"]?'
+ mapfile -t values
++ jq -r '.jobs[]?."job options"["filesize"]?' /tmp/create_benchmark_tables.dKkjUd/gcsfuse-sequential-read-workload-benchmark_1.json
+ local i
+ for i in "${!values[@]}"
+ local value=128K
+ [[ 128K == \n\u\l\l ]]
+ [[ 128K == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=256K
+ [[ 256K == \n\u\l\l ]]
+ [[ 256K == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=1MB
+ [[ 1MB == \n\u\l\l ]]
+ [[ 1MB == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=5MB
+ [[ 5MB == \n\u\l\l ]]
+ [[ 5MB == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=10MB
+ [[ 10MB == \n\u\l\l ]]
+ [[ 10MB == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=50MB
+ [[ 50MB == \n\u\l\l ]]
+ [[ 50MB == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=100MB
+ [[ 100MB == \n\u\l\l ]]
+ [[ 100MB == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=200MB
+ [[ 200MB == \n\u\l\l ]]
+ [[ 200MB == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=1GB
+ [[ 1GB == \n\u\l\l ]]
+ [[ 1GB == \n\u\l\l ]]
+ array_ref+=("$value")
+ [[ 9 -ne 9 ]]
+ populate_array_from_jq /tmp/create_benchmark_tables.dKkjUd/gcsfuse-sequential-read-workload-benchmark_1.json '.jobs[]?."job options"' '."global options"' nrfiles nrfiles
+ local file=/tmp/create_benchmark_tables.dKkjUd/gcsfuse-sequential-read-workload-benchmark_1.json
+ local 'jq_job_path_template=.jobs[]?."job options"'
+ local 'jq_global_path_template=."global options"'
+ local field_name=nrfiles
+ local -n array_ref=nrfiles
+ array_ref=()
+ local 'jq_job_query=.jobs[]?."job options"["nrfiles"]?'
+ local 'jq_global_query=."global options"["nrfiles"]?'
+ mapfile -t values
++ jq -r '.jobs[]?."job options"["nrfiles"]?' /tmp/create_benchmark_tables.dKkjUd/gcsfuse-sequential-read-workload-benchmark_1.json
+ local i
+ for i in "${!values[@]}"
+ local value=30
+ [[ 30 == \n\u\l\l ]]
+ [[ 30 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=30
+ [[ 30 == \n\u\l\l ]]
+ [[ 30 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=30
+ [[ 30 == \n\u\l\l ]]
+ [[ 30 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=20
+ [[ 20 == \n\u\l\l ]]
+ [[ 20 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=20
+ [[ 20 == \n\u\l\l ]]
+ [[ 20 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=20
+ [[ 20 == \n\u\l\l ]]
+ [[ 20 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=10
+ [[ 10 == \n\u\l\l ]]
+ [[ 10 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=10
+ [[ 10 == \n\u\l\l ]]
+ [[ 10 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=10
+ [[ 10 == \n\u\l\l ]]
+ [[ 10 == \n\u\l\l ]]
+ array_ref+=("$value")
+ [[ 9 -ne 9 ]]
+ populate_avg_in_array_for_all_runs /tmp/create_benchmark_tables.dKkjUd/gcsfuse-sequential-read-workload-benchmark '.jobs[]?.read' '."global options"' bw_bytes bw_bytes
+ local file=/tmp/create_benchmark_tables.dKkjUd/gcsfuse-sequential-read-workload-benchmark
+ local 'jq_job_path_template=.jobs[]?.read'
+ local 'jq_global_path_template=."global options"'
+ local field_name=bw_bytes
+ local -n array_ref=bw_bytes
+ sum=()
+ local sum
++ seq 1 1
+ for i in $(seq 1 "$BENCHMARK_COUNT")
+ curr_arr=()
+ local curr_arr
+ local curr_file_name=/tmp/create_benchmark_tables.dKkjUd/gcsfuse-sequential-read-workload-benchmark_1.json
+ populate_array_from_jq /tmp/create_benchmark_tables.dKkjUd/gcsfuse-sequential-read-workload-benchmark_1.json '.jobs[]?.read' '."global options"' bw_bytes curr_arr
+ local file=/tmp/create_benchmark_tables.dKkjUd/gcsfuse-sequential-read-workload-benchmark_1.json
+ local 'jq_job_path_template=.jobs[]?.read'
+ local 'jq_global_path_template=."global options"'
+ local field_name=bw_bytes
+ local -n array_ref=curr_arr
+ array_ref=()
+ local 'jq_job_query=.jobs[]?.read["bw_bytes"]?'
+ local 'jq_global_query=."global options"["bw_bytes"]?'
+ mapfile -t values
++ jq -r '.jobs[]?.read["bw_bytes"]?' /tmp/create_benchmark_tables.dKkjUd/gcsfuse-sequential-read-workload-benchmark_1.json
+ local i
+ for i in "${!values[@]}"
+ local value=827823157
+ [[ 827823157 == \n\u\l\l ]]
+ [[ 827823157 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=1427848170
+ [[ 1427848170 == \n\u\l\l ]]
+ [[ 1427848170 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=5569200331
+ [[ 5569200331 == \n\u\l\l ]]
+ [[ 5569200331 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=8772400522
+ [[ 8772400522 == \n\u\l\l ]]
+ [[ 8772400522 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=11919869271
+ [[ 11919869271 == \n\u\l\l ]]
+ [[ 11919869271 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=17169979275
+ [[ 17169979275 == \n\u\l\l ]]
+ [[ 17169979275 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=16957388250
+ [[ 16957388250 == \n\u\l\l ]]
+ [[ 16957388250 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=17182068488
+ [[ 17182068488 == \n\u\l\l ]]
+ [[ 17182068488 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=15516675526
+ [[ 15516675526 == \n\u\l\l ]]
+ [[ 15516675526 == \n\u\l\l ]]
+ array_ref+=("$value")
+ [[ 9 -ne 9 ]]
+ [[ 1 -eq 1 ]]
+ sum=("${curr_arr[@]}")
+ (( i = 0 ))
+ (( i < ROW_COUNT ))
++ awk -v s=827823157 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=827823157
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=1427848170 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=1427848170
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=5569200331 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=5569200331
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=8772400522 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=8772400522
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=11919869271 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=11919869271
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=17169979275 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=17169979275
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=16957388250 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=16957388250
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=17182068488 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=17182068488
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=15516675526 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=15516675526
+ (( i++ ))
+ (( i < ROW_COUNT ))
+ populate_avg_in_array_for_all_runs /tmp/create_benchmark_tables.dKkjUd/gcsfuse-sequential-read-workload-benchmark '.jobs[]?.read' '."global options"' iops iops
+ local file=/tmp/create_benchmark_tables.dKkjUd/gcsfuse-sequential-read-workload-benchmark
+ local 'jq_job_path_template=.jobs[]?.read'
+ local 'jq_global_path_template=."global options"'
+ local field_name=iops
+ local -n array_ref=iops
+ sum=()
+ local sum
++ seq 1 1
+ for i in $(seq 1 "$BENCHMARK_COUNT")
+ curr_arr=()
+ local curr_arr
+ local curr_file_name=/tmp/create_benchmark_tables.dKkjUd/gcsfuse-sequential-read-workload-benchmark_1.json
+ populate_array_from_jq /tmp/create_benchmark_tables.dKkjUd/gcsfuse-sequential-read-workload-benchmark_1.json '.jobs[]?.read' '."global options"' iops curr_arr
+ local file=/tmp/create_benchmark_tables.dKkjUd/gcsfuse-sequential-read-workload-benchmark_1.json
+ local 'jq_job_path_template=.jobs[]?.read'
+ local 'jq_global_path_template=."global options"'
+ local field_name=iops
+ local -n array_ref=curr_arr
+ array_ref=()
+ local 'jq_job_query=.jobs[]?.read["iops"]?'
+ local 'jq_global_query=."global options"["iops"]?'
+ mapfile -t values
++ jq -r '.jobs[]?.read["iops"]?' /tmp/create_benchmark_tables.dKkjUd/gcsfuse-sequential-read-workload-benchmark_1.json
+ local i
+ for i in "${!values[@]}"
+ local value=6315.789474
+ [[ 6315.789474 == \n\u\l\l ]]
+ [[ 6315.789474 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=10893.617021
+ [[ 10893.617021 == \n\u\l\l ]]
+ [[ 10893.617021 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=5311.203320
+ [[ 5311.203320 == \n\u\l\l ]]
+ [[ 5311.203320 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=8366.013072
+ [[ 8366.013072 == \n\u\l\l ]]
+ [[ 8366.013072 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=11367.673179
+ [[ 11367.673179 == \n\u\l\l ]]
+ [[ 11367.673179 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=16374.568249
+ [[ 16374.568249 == \n\u\l\l ]]
+ [[ 16374.568249 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=16171.825648
+ [[ 16171.825648 == \n\u\l\l ]]
+ [[ 16171.825648 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=16386.097420
+ [[ 16386.097420 == \n\u\l\l ]]
+ [[ 16386.097420 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=14797.854925
+ [[ 14797.854925 == \n\u\l\l ]]
+ [[ 14797.854925 == \n\u\l\l ]]
+ array_ref+=("$value")
+ [[ 9 -ne 9 ]]
+ [[ 1 -eq 1 ]]
+ sum=("${curr_arr[@]}")
+ (( i = 0 ))
+ (( i < ROW_COUNT ))
++ awk -v s=6315.789474 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=6315.79
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=10893.617021 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=10893.6
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=5311.203320 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=5311.2
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=8366.013072 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=8366.01
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=11367.673179 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=11367.7
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=16374.568249 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=16374.6
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=16171.825648 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=16171.8
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=16386.097420 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=16386.1
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=14797.854925 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=14797.9
+ (( i++ ))
+ (( i < ROW_COUNT ))
+ populate_avg_in_array_for_all_runs /tmp/create_benchmark_tables.dKkjUd/gcsfuse-sequential-read-workload-benchmark '.jobs[]?.read.lat_ns' '."global options"' mean lat_mean
+ local file=/tmp/create_benchmark_tables.dKkjUd/gcsfuse-sequential-read-workload-benchmark
+ local 'jq_job_path_template=.jobs[]?.read.lat_ns'
+ local 'jq_global_path_template=."global options"'
+ local field_name=mean
+ local -n array_ref=lat_mean
+ sum=()
+ local sum
++ seq 1 1
+ for i in $(seq 1 "$BENCHMARK_COUNT")
+ curr_arr=()
+ local curr_arr
+ local curr_file_name=/tmp/create_benchmark_tables.dKkjUd/gcsfuse-sequential-read-workload-benchmark_1.json
+ populate_array_from_jq /tmp/create_benchmark_tables.dKkjUd/gcsfuse-sequential-read-workload-benchmark_1.json '.jobs[]?.read.lat_ns' '."global options"' mean curr_arr
+ local file=/tmp/create_benchmark_tables.dKkjUd/gcsfuse-sequential-read-workload-benchmark_1.json
+ local 'jq_job_path_template=.jobs[]?.read.lat_ns'
+ local 'jq_global_path_template=."global options"'
+ local field_name=mean
+ local -n array_ref=curr_arr
+ array_ref=()
+ local 'jq_job_query=.jobs[]?.read.lat_ns["mean"]?'
+ local 'jq_global_query=."global options"["mean"]?'
+ mapfile -t values
++ jq -r '.jobs[]?.read.lat_ns["mean"]?' /tmp/create_benchmark_tables.dKkjUd/gcsfuse-sequential-read-workload-benchmark_1.json
+ local i
+ for i in "${!values[@]}"
+ local value=16200872.907552
+ [[ 16200872.907552 == \n\u\l\l ]]
+ [[ 16200872.907552 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=8931084.167057
+ [[ 8931084.167057 == \n\u\l\l ]]
+ [[ 8931084.167057 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=20521273.168490
+ [[ 20521273.168490 == \n\u\l\l ]]
+ [[ 20521273.168490 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=14158451.597031
+ [[ 14158451.597031 == \n\u\l\l ]]
+ [[ 14158451.597031 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=12126026.447891
+ [[ 12126026.447891 == \n\u\l\l ]]
+ [[ 12126026.447891 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=12726413.590492
+ [[ 12726413.590492 == \n\u\l\l ]]
+ [[ 12726413.590492 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=27015235.963180
+ [[ 27015235.963180 == \n\u\l\l ]]
+ [[ 27015235.963180 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=33862245.369453
+ [[ 33862245.369453 == \n\u\l\l ]]
+ [[ 33862245.369453 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=54485476.093236
+ [[ 54485476.093236 == \n\u\l\l ]]
+ [[ 54485476.093236 == \n\u\l\l ]]
+ array_ref+=("$value")
+ [[ 9 -ne 9 ]]
+ [[ 1 -eq 1 ]]
+ sum=("${curr_arr[@]}")
+ (( i = 0 ))
+ (( i < ROW_COUNT ))
++ awk -v s=16200872.907552 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=1.62009e+07
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=8931084.167057 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=8.93108e+06
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=20521273.168490 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=2.05213e+07
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=14158451.597031 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=1.41585e+07
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=12126026.447891 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=1.2126e+07
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=12726413.590492 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=1.27264e+07
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=27015235.963180 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=2.70152e+07
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=33862245.369453 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=3.38622e+07
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=54485476.093236 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=5.44855e+07
+ (( i++ ))
+ (( i < ROW_COUNT ))
+ convert_bytes_to GB
+ local division=1000000000
+ local precision=3
+ (( i = 0 ))
+ (( i < ROW_COUNT ))
++ awk -v prec=3 -v div=1000000000 -v bval=827823157 'BEGIN { printf "%.*f\n", prec, bval / div }'
+ bw_bytes[i]=0.828
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v prec=3 -v div=1000000000 -v bval=1427848170 'BEGIN { printf "%.*f\n", prec, bval / div }'
+ bw_bytes[i]=1.428
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v prec=3 -v div=1000000000 -v bval=5569200331 'BEGIN { printf "%.*f\n", prec, bval / div }'
+ bw_bytes[i]=5.569
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v prec=3 -v div=1000000000 -v bval=8772400522 'BEGIN { printf "%.*f\n", prec, bval / div }'
+ bw_bytes[i]=8.772
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v prec=3 -v div=1000000000 -v bval=11919869271 'BEGIN { printf "%.*f\n", prec, bval / div }'
+ bw_bytes[i]=11.920
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v prec=3 -v div=1000000000 -v bval=17169979275 'BEGIN { printf "%.*f\n", prec, bval / div }'
+ bw_bytes[i]=17.170
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v prec=3 -v div=1000000000 -v bval=16957388250 'BEGIN { printf "%.*f\n", prec, bval / div }'
+ bw_bytes[i]=16.957
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v prec=3 -v div=1000000000 -v bval=17182068488 'BEGIN { printf "%.*f\n", prec, bval / div }'
+ bw_bytes[i]=17.182
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v prec=3 -v div=1000000000 -v bval=15516675526 'BEGIN { printf "%.*f\n", prec, bval / div }'
+ bw_bytes[i]=15.517
+ (( i++ ))
+ (( i < ROW_COUNT ))
+ format_iops_to_kilo
+ (( i = 0 ))
+ (( i < ROW_COUNT ))
++ awk -v n=6315.79 'BEGIN { printf "%.2fK\n", n / 1000 }'
+ iops[i]=6.32K
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v n=10893.6 'BEGIN { printf "%.2fK\n", n / 1000 }'
+ iops[i]=10.89K
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v n=5311.2 'BEGIN { printf "%.2fK\n", n / 1000 }'
+ iops[i]=5.31K
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v n=8366.01 'BEGIN { printf "%.2fK\n", n / 1000 }'
+ iops[i]=8.37K
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v n=11367.7 'BEGIN { printf "%.2fK\n", n / 1000 }'
+ iops[i]=11.37K
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v n=16374.6 'BEGIN { printf "%.2fK\n", n / 1000 }'
+ iops[i]=16.37K
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v n=16171.8 'BEGIN { printf "%.2fK\n", n / 1000 }'
+ iops[i]=16.17K
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v n=16386.1 'BEGIN { printf "%.2fK\n", n / 1000 }'
+ iops[i]=16.39K
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v n=14797.9 'BEGIN { printf "%.2fK\n", n / 1000 }'
+ iops[i]=14.80K
+ (( i++ ))
+ (( i < ROW_COUNT ))
+ convert_lat_mean_ns_to_ms lat_mean
+ local -n lat_array_ref=lat_mean
+ local precision=2
+ (( i = 0 ))
+ (( i < ROW_COUNT ))
++ awk -v p=2 -v ns=1.62009e+07 'BEGIN { printf "%.*fms\n", p, ns / 1E6 }'
+ lat_array_ref[i]=16.20ms
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v p=2 -v ns=8.93108e+06 'BEGIN { printf "%.*fms\n", p, ns / 1E6 }'
+ lat_array_ref[i]=8.93ms
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v p=2 -v ns=2.05213e+07 'BEGIN { printf "%.*fms\n", p, ns / 1E6 }'
+ lat_array_ref[i]=20.52ms
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v p=2 -v ns=1.41585e+07 'BEGIN { printf "%.*fms\n", p, ns / 1E6 }'
+ lat_array_ref[i]=14.16ms
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v p=2 -v ns=1.2126e+07 'BEGIN { printf "%.*fms\n", p, ns / 1E6 }'
+ lat_array_ref[i]=12.13ms
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v p=2 -v ns=1.27264e+07 'BEGIN { printf "%.*fms\n", p, ns / 1E6 }'
+ lat_array_ref[i]=12.73ms
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v p=2 -v ns=2.70152e+07 'BEGIN { printf "%.*fms\n", p, ns / 1E6 }'
+ lat_array_ref[i]=27.02ms
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v p=2 -v ns=3.38622e+07 'BEGIN { printf "%.*fms\n", p, ns / 1E6 }'
+ lat_array_ref[i]=33.86ms
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v p=2 -v ns=5.44855e+07 'BEGIN { printf "%.*fms\n", p, ns / 1E6 }'
+ lat_array_ref[i]=54.49ms
+ (( i++ ))
+ (( i < ROW_COUNT ))
+ echo '| File Size | BlockSize | nrfiles | Bandwidth in (GB/sec) | IOPs | IOPs Avg Latency (ms) |'
+ echo '|---|---|---|---|---|---|'
+ (( i = 0 ))
+ (( i < ROW_COUNT ))
+ echo '| 128K | 128K | 30 | 0.828 | 6.32K | 16.20ms |'
+ (( i++ ))
+ (( i < ROW_COUNT ))
+ echo '| 256K | 128K | 30 | 1.428 | 10.89K | 8.93ms |'
+ (( i++ ))
+ (( i < ROW_COUNT ))
+ echo '| 1MB | 1M | 30 | 5.569 | 5.31K | 20.52ms |'
+ (( i++ ))
+ (( i < ROW_COUNT ))
+ echo '| 5MB | 1M | 20 | 8.772 | 8.37K | 14.16ms |'
+ (( i++ ))
+ (( i < ROW_COUNT ))
+ echo '| 10MB | 1M | 20 | 11.920 | 11.37K | 12.13ms |'
+ (( i++ ))
+ (( i < ROW_COUNT ))
+ echo '| 50MB | 1M | 20 | 17.170 | 16.37K | 12.73ms |'
+ (( i++ ))
+ (( i < ROW_COUNT ))
+ echo '| 100MB | 1M | 10 | 16.957 | 16.17K | 27.02ms |'
+ (( i++ ))
+ (( i < ROW_COUNT ))
+ echo '| 200MB | 1M | 10 | 17.182 | 16.39K | 33.86ms |'
+ (( i++ ))
+ (( i < ROW_COUNT ))
+ echo '| 1GB | 1M | 10 | 15.517 | 14.80K | 54.49ms |'
+ (( i++ ))
+ (( i < ROW_COUNT ))
+ echo ''
+ create_table 'Random Reads' /tmp/create_benchmark_tables.dKkjUd/gcsfuse-random-read-workload-benchmark read MB
+ local 'table_name=Random Reads'
+ local file=/tmp/create_benchmark_tables.dKkjUd/gcsfuse-random-read-workload-benchmark
+ local workflow_type=read
+ local bw_in=MB
+ echo '### Random Reads'
++ job_count /tmp/create_benchmark_tables.dKkjUd/gcsfuse-random-read-workload-benchmark_1.json
++ local file=/tmp/create_benchmark_tables.dKkjUd/gcsfuse-random-read-workload-benchmark_1.json
++ local count
+++ jq '.jobs | length' /tmp/create_benchmark_tables.dKkjUd/gcsfuse-random-read-workload-benchmark_1.json
++ count=9
++ [[ 9 -le 0 ]]
++ echo 9
+ ROW_COUNT=9
+ populate_all_columns /tmp/create_benchmark_tables.dKkjUd/gcsfuse-random-read-workload-benchmark read
+ local file=/tmp/create_benchmark_tables.dKkjUd/gcsfuse-random-read-workload-benchmark
+ local op_type=read
+ local lat_ns_op_type=read.lat_ns
+ populate_array_from_jq /tmp/create_benchmark_tables.dKkjUd/gcsfuse-random-read-workload-benchmark_1.json '.jobs[]?."job options"' '."global options"' bs bs
+ local file=/tmp/create_benchmark_tables.dKkjUd/gcsfuse-random-read-workload-benchmark_1.json
+ local 'jq_job_path_template=.jobs[]?."job options"'
+ local 'jq_global_path_template=."global options"'
+ local field_name=bs
+ local -n array_ref=bs
+ array_ref=()
+ local 'jq_job_query=.jobs[]?."job options"["bs"]?'
+ local 'jq_global_query=."global options"["bs"]?'
+ mapfile -t values
++ jq -r '.jobs[]?."job options"["bs"]?' /tmp/create_benchmark_tables.dKkjUd/gcsfuse-random-read-workload-benchmark_1.json
+ local i
+ for i in "${!values[@]}"
+ local value=128K
+ [[ 128K == \n\u\l\l ]]
+ [[ 128K == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=128K
+ [[ 128K == \n\u\l\l ]]
+ [[ 128K == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=1M
+ [[ 1M == \n\u\l\l ]]
+ [[ 1M == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=1M
+ [[ 1M == \n\u\l\l ]]
+ [[ 1M == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=1M
+ [[ 1M == \n\u\l\l ]]
+ [[ 1M == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=1M
+ [[ 1M == \n\u\l\l ]]
+ [[ 1M == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=1M
+ [[ 1M == \n\u\l\l ]]
+ [[ 1M == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=1M
+ [[ 1M == \n\u\l\l ]]
+ [[ 1M == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=1M
+ [[ 1M == \n\u\l\l ]]
+ [[ 1M == \n\u\l\l ]]
+ array_ref+=("$value")
+ [[ 9 -ne 9 ]]
+ populate_array_from_jq /tmp/create_benchmark_tables.dKkjUd/gcsfuse-random-read-workload-benchmark_1.json '.jobs[]?."job options"' '."global options"' filesize filesize
+ local file=/tmp/create_benchmark_tables.dKkjUd/gcsfuse-random-read-workload-benchmark_1.json
+ local 'jq_job_path_template=.jobs[]?."job options"'
+ local 'jq_global_path_template=."global options"'
+ local field_name=filesize
+ local -n array_ref=filesize
+ array_ref=()
+ local 'jq_job_query=.jobs[]?."job options"["filesize"]?'
+ local 'jq_global_query=."global options"["filesize"]?'
+ mapfile -t values
++ jq -r '.jobs[]?."job options"["filesize"]?' /tmp/create_benchmark_tables.dKkjUd/gcsfuse-random-read-workload-benchmark_1.json
+ local i
+ for i in "${!values[@]}"
+ local value=128K
+ [[ 128K == \n\u\l\l ]]
+ [[ 128K == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=256K
+ [[ 256K == \n\u\l\l ]]
+ [[ 256K == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=1MB
+ [[ 1MB == \n\u\l\l ]]
+ [[ 1MB == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=5MB
+ [[ 5MB == \n\u\l\l ]]
+ [[ 5MB == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=10MB
+ [[ 10MB == \n\u\l\l ]]
+ [[ 10MB == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=50MB
+ [[ 50MB == \n\u\l\l ]]
+ [[ 50MB == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=100MB
+ [[ 100MB == \n\u\l\l ]]
+ [[ 100MB == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=200MB
+ [[ 200MB == \n\u\l\l ]]
+ [[ 200MB == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=1GB
+ [[ 1GB == \n\u\l\l ]]
+ [[ 1GB == \n\u\l\l ]]
+ array_ref+=("$value")
+ [[ 9 -ne 9 ]]
+ populate_array_from_jq /tmp/create_benchmark_tables.dKkjUd/gcsfuse-random-read-workload-benchmark_1.json '.jobs[]?."job options"' '."global options"' nrfiles nrfiles
+ local file=/tmp/create_benchmark_tables.dKkjUd/gcsfuse-random-read-workload-benchmark_1.json
+ local 'jq_job_path_template=.jobs[]?."job options"'
+ local 'jq_global_path_template=."global options"'
+ local field_name=nrfiles
+ local -n array_ref=nrfiles
+ array_ref=()
+ local 'jq_job_query=.jobs[]?."job options"["nrfiles"]?'
+ local 'jq_global_query=."global options"["nrfiles"]?'
+ mapfile -t values
++ jq -r '.jobs[]?."job options"["nrfiles"]?' /tmp/create_benchmark_tables.dKkjUd/gcsfuse-random-read-workload-benchmark_1.json
+ local i
+ for i in "${!values[@]}"
+ local value=30
+ [[ 30 == \n\u\l\l ]]
+ [[ 30 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=30
+ [[ 30 == \n\u\l\l ]]
+ [[ 30 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=30
+ [[ 30 == \n\u\l\l ]]
+ [[ 30 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=20
+ [[ 20 == \n\u\l\l ]]
+ [[ 20 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=20
+ [[ 20 == \n\u\l\l ]]
+ [[ 20 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=20
+ [[ 20 == \n\u\l\l ]]
+ [[ 20 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=10
+ [[ 10 == \n\u\l\l ]]
+ [[ 10 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=10
+ [[ 10 == \n\u\l\l ]]
+ [[ 10 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=10
+ [[ 10 == \n\u\l\l ]]
+ [[ 10 == \n\u\l\l ]]
+ array_ref+=("$value")
+ [[ 9 -ne 9 ]]
+ populate_avg_in_array_for_all_runs /tmp/create_benchmark_tables.dKkjUd/gcsfuse-random-read-workload-benchmark '.jobs[]?.read' '."global options"' bw_bytes bw_bytes
+ local file=/tmp/create_benchmark_tables.dKkjUd/gcsfuse-random-read-workload-benchmark
+ local 'jq_job_path_template=.jobs[]?.read'
+ local 'jq_global_path_template=."global options"'
+ local field_name=bw_bytes
+ local -n array_ref=bw_bytes
+ sum=()
+ local sum
++ seq 1 1
+ for i in $(seq 1 "$BENCHMARK_COUNT")
+ curr_arr=()
+ local curr_arr
+ local curr_file_name=/tmp/create_benchmark_tables.dKkjUd/gcsfuse-random-read-workload-benchmark_1.json
+ populate_array_from_jq /tmp/create_benchmark_tables.dKkjUd/gcsfuse-random-read-workload-benchmark_1.json '.jobs[]?.read' '."global options"' bw_bytes curr_arr
+ local file=/tmp/create_benchmark_tables.dKkjUd/gcsfuse-random-read-workload-benchmark_1.json
+ local 'jq_job_path_template=.jobs[]?.read'
+ local 'jq_global_path_template=."global options"'
+ local field_name=bw_bytes
+ local -n array_ref=curr_arr
+ array_ref=()
+ local 'jq_job_query=.jobs[]?.read["bw_bytes"]?'
+ local 'jq_global_query=."global options"["bw_bytes"]?'
+ mapfile -t values
++ jq -r '.jobs[]?.read["bw_bytes"]?' /tmp/create_benchmark_tables.dKkjUd/gcsfuse-random-read-workload-benchmark_1.json
+ local i
+ for i in "${!values[@]}"
+ local value=940778467
+ [[ 940778467 == \n\u\l\l ]]
+ [[ 940778467 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=997654073
+ [[ 997654073 == \n\u\l\l ]]
+ [[ 997654073 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=4793490285
+ [[ 4793490285 == \n\u\l\l ]]
+ [[ 4793490285 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=5144412725
+ [[ 5144412725 == \n\u\l\l ]]
+ [[ 5144412725 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=5336688986
+ [[ 5336688986 == \n\u\l\l ]]
+ [[ 5336688986 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=4499571826
+ [[ 4499571826 == \n\u\l\l ]]
+ [[ 4499571826 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=4029836305
+ [[ 4029836305 == \n\u\l\l ]]
+ [[ 4029836305 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=3801232773
+ [[ 3801232773 == \n\u\l\l ]]
+ [[ 3801232773 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=2454249495
+ [[ 2454249495 == \n\u\l\l ]]
+ [[ 2454249495 == \n\u\l\l ]]
+ array_ref+=("$value")
+ [[ 9 -ne 9 ]]
+ [[ 1 -eq 1 ]]
+ sum=("${curr_arr[@]}")
+ (( i = 0 ))
+ (( i < ROW_COUNT ))
++ awk -v s=940778467 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=940778467
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=997654073 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=997654073
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=4793490285 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=4793490285
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=5144412725 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=5144412725
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=5336688986 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=5336688986
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=4499571826 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=4499571826
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=4029836305 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=4029836305
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=3801232773 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=3801232773
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=2454249495 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=2454249495
+ (( i++ ))
+ (( i < ROW_COUNT ))
+ populate_avg_in_array_for_all_runs /tmp/create_benchmark_tables.dKkjUd/gcsfuse-random-read-workload-benchmark '.jobs[]?.read' '."global options"' iops iops
+ local file=/tmp/create_benchmark_tables.dKkjUd/gcsfuse-random-read-workload-benchmark
+ local 'jq_job_path_template=.jobs[]?.read'
+ local 'jq_global_path_template=."global options"'
+ local field_name=iops
+ local -n array_ref=iops
+ sum=()
+ local sum
++ seq 1 1
+ for i in $(seq 1 "$BENCHMARK_COUNT")
+ curr_arr=()
+ local curr_arr
+ local curr_file_name=/tmp/create_benchmark_tables.dKkjUd/gcsfuse-random-read-workload-benchmark_1.json
+ populate_array_from_jq /tmp/create_benchmark_tables.dKkjUd/gcsfuse-random-read-workload-benchmark_1.json '.jobs[]?.read' '."global options"' iops curr_arr
+ local file=/tmp/create_benchmark_tables.dKkjUd/gcsfuse-random-read-workload-benchmark_1.json
+ local 'jq_job_path_template=.jobs[]?.read'
+ local 'jq_global_path_template=."global options"'
+ local field_name=iops
+ local -n array_ref=curr_arr
+ array_ref=()
+ local 'jq_job_query=.jobs[]?.read["iops"]?'
+ local 'jq_global_query=."global options"["iops"]?'
+ mapfile -t values
++ jq -r '.jobs[]?.read["iops"]?' /tmp/create_benchmark_tables.dKkjUd/gcsfuse-random-read-workload-benchmark_1.json
+ local i
+ for i in "${!values[@]}"
+ local value=7177.570093
+ [[ 7177.570093 == \n\u\l\l ]]
+ [[ 7177.570093 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=7611.496531
+ [[ 7611.496531 == \n\u\l\l ]]
+ [[ 7611.496531 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=4571.428571
+ [[ 4571.428571 == \n\u\l\l ]]
+ [[ 4571.428571 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=4906.094289
+ [[ 4906.094289 == \n\u\l\l ]]
+ [[ 4906.094289 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=5089.463221
+ [[ 5089.463221 == \n\u\l\l ]]
+ [[ 5089.463221 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=4291.126085
+ [[ 4291.126085 == \n\u\l\l ]]
+ [[ 4291.126085 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=3843.151384
+ [[ 3843.151384 == \n\u\l\l ]]
+ [[ 3843.151384 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=3625.138067
+ [[ 3625.138067 == \n\u\l\l ]]
+ [[ 3625.138067 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=2340.554710
+ [[ 2340.554710 == \n\u\l\l ]]
+ [[ 2340.554710 == \n\u\l\l ]]
+ array_ref+=("$value")
+ [[ 9 -ne 9 ]]
+ [[ 1 -eq 1 ]]
+ sum=("${curr_arr[@]}")
+ (( i = 0 ))
+ (( i < ROW_COUNT ))
++ awk -v s=7177.570093 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=7177.57
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=7611.496531 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=7611.5
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=4571.428571 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=4571.43
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=4906.094289 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=4906.09
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=5089.463221 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=5089.46
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=4291.126085 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=4291.13
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=3843.151384 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=3843.15
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=3625.138067 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=3625.14
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=2340.554710 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=2340.55
+ (( i++ ))
+ (( i < ROW_COUNT ))
+ populate_avg_in_array_for_all_runs /tmp/create_benchmark_tables.dKkjUd/gcsfuse-random-read-workload-benchmark '.jobs[]?.read.lat_ns' '."global options"' mean lat_mean
+ local file=/tmp/create_benchmark_tables.dKkjUd/gcsfuse-random-read-workload-benchmark
+ local 'jq_job_path_template=.jobs[]?.read.lat_ns'
+ local 'jq_global_path_template=."global options"'
+ local field_name=mean
+ local -n array_ref=lat_mean
+ sum=()
+ local sum
++ seq 1 1
+ for i in $(seq 1 "$BENCHMARK_COUNT")
+ curr_arr=()
+ local curr_arr
+ local curr_file_name=/tmp/create_benchmark_tables.dKkjUd/gcsfuse-random-read-workload-benchmark_1.json
+ populate_array_from_jq /tmp/create_benchmark_tables.dKkjUd/gcsfuse-random-read-workload-benchmark_1.json '.jobs[]?.read.lat_ns' '."global options"' mean curr_arr
+ local file=/tmp/create_benchmark_tables.dKkjUd/gcsfuse-random-read-workload-benchmark_1.json
+ local 'jq_job_path_template=.jobs[]?.read.lat_ns'
+ local 'jq_global_path_template=."global options"'
+ local field_name=mean
+ local -n array_ref=curr_arr
+ array_ref=()
+ local 'jq_job_query=.jobs[]?.read.lat_ns["mean"]?'
+ local 'jq_global_query=."global options"["mean"]?'
+ mapfile -t values
++ jq -r '.jobs[]?.read.lat_ns["mean"]?' /tmp/create_benchmark_tables.dKkjUd/gcsfuse-random-read-workload-benchmark_1.json
+ local i
+ for i in "${!values[@]}"
+ local value=15194233.740625
+ [[ 15194233.740625 == \n\u\l\l ]]
+ [[ 15194233.740625 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=14956940.776563
+ [[ 14956940.776563 == \n\u\l\l ]]
+ [[ 14956940.776563 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=21693161.895573
+ [[ 21693161.895573 == \n\u\l\l ]]
+ [[ 21693161.895573 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=26558757.256562
+ [[ 26558757.256562 == \n\u\l\l ]]
+ [[ 26558757.256562 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=31876941.669102
+ [[ 31876941.669102 == \n\u\l\l ]]
+ [[ 31876941.669102 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=70249321.523219
+ [[ 70249321.523219 == \n\u\l\l ]]
+ [[ 70249321.523219 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=177932315.073602
+ [[ 177932315.073602 == \n\u\l\l ]]
+ [[ 177932315.073602 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=246281291.959711
+ [[ 246281291.959711 == \n\u\l\l ]]
+ [[ 246281291.959711 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=519394001.246655
+ [[ 519394001.246655 == \n\u\l\l ]]
+ [[ 519394001.246655 == \n\u\l\l ]]
+ array_ref+=("$value")
+ [[ 9 -ne 9 ]]
+ [[ 1 -eq 1 ]]
+ sum=("${curr_arr[@]}")
+ (( i = 0 ))
+ (( i < ROW_COUNT ))
++ awk -v s=15194233.740625 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=1.51942e+07
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=14956940.776563 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=1.49569e+07
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=21693161.895573 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=2.16932e+07
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=26558757.256562 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=2.65588e+07
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=31876941.669102 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=3.18769e+07
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=70249321.523219 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=7.02493e+07
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=177932315.073602 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=1.77932e+08
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=246281291.959711 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=2.46281e+08
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=519394001.246655 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=5.19394e+08
+ (( i++ ))
+ (( i < ROW_COUNT ))
+ convert_bytes_to MB
+ local division=1000000
+ local precision=3
+ (( i = 0 ))
+ (( i < ROW_COUNT ))
++ awk -v prec=3 -v div=1000000 -v bval=940778467 'BEGIN { printf "%.*f\n", prec, bval / div }'
+ bw_bytes[i]=940.778
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v prec=3 -v div=1000000 -v bval=997654073 'BEGIN { printf "%.*f\n", prec, bval / div }'
+ bw_bytes[i]=997.654
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v prec=3 -v div=1000000 -v bval=4793490285 'BEGIN { printf "%.*f\n", prec, bval / div }'
+ bw_bytes[i]=4793.490
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v prec=3 -v div=1000000 -v bval=5144412725 'BEGIN { printf "%.*f\n", prec, bval / div }'
+ bw_bytes[i]=5144.413
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v prec=3 -v div=1000000 -v bval=5336688986 'BEGIN { printf "%.*f\n", prec, bval / div }'
+ bw_bytes[i]=5336.689
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v prec=3 -v div=1000000 -v bval=4499571826 'BEGIN { printf "%.*f\n", prec, bval / div }'
+ bw_bytes[i]=4499.572
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v prec=3 -v div=1000000 -v bval=4029836305 'BEGIN { printf "%.*f\n", prec, bval / div }'
+ bw_bytes[i]=4029.836
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v prec=3 -v div=1000000 -v bval=3801232773 'BEGIN { printf "%.*f\n", prec, bval / div }'
+ bw_bytes[i]=3801.233
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v prec=3 -v div=1000000 -v bval=2454249495 'BEGIN { printf "%.*f\n", prec, bval / div }'
+ bw_bytes[i]=2454.249
+ (( i++ ))
+ (( i < ROW_COUNT ))
+ format_iops_to_kilo
+ (( i = 0 ))
+ (( i < ROW_COUNT ))
++ awk -v n=7177.57 'BEGIN { printf "%.2fK\n", n / 1000 }'
+ iops[i]=7.18K
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v n=7611.5 'BEGIN { printf "%.2fK\n", n / 1000 }'
+ iops[i]=7.61K
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v n=4571.43 'BEGIN { printf "%.2fK\n", n / 1000 }'
+ iops[i]=4.57K
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v n=4906.09 'BEGIN { printf "%.2fK\n", n / 1000 }'
+ iops[i]=4.91K
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v n=5089.46 'BEGIN { printf "%.2fK\n", n / 1000 }'
+ iops[i]=5.09K
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v n=4291.13 'BEGIN { printf "%.2fK\n", n / 1000 }'
+ iops[i]=4.29K
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v n=3843.15 'BEGIN { printf "%.2fK\n", n / 1000 }'
+ iops[i]=3.84K
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v n=3625.14 'BEGIN { printf "%.2fK\n", n / 1000 }'
+ iops[i]=3.63K
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v n=2340.55 'BEGIN { printf "%.2fK\n", n / 1000 }'
+ iops[i]=2.34K
+ (( i++ ))
+ (( i < ROW_COUNT ))
+ convert_lat_mean_ns_to_ms lat_mean
+ local -n lat_array_ref=lat_mean
+ local precision=2
+ (( i = 0 ))
+ (( i < ROW_COUNT ))
++ awk -v p=2 -v ns=1.51942e+07 'BEGIN { printf "%.*fms\n", p, ns / 1E6 }'
+ lat_array_ref[i]=15.19ms
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v p=2 -v ns=1.49569e+07 'BEGIN { printf "%.*fms\n", p, ns / 1E6 }'
+ lat_array_ref[i]=14.96ms
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v p=2 -v ns=2.16932e+07 'BEGIN { printf "%.*fms\n", p, ns / 1E6 }'
+ lat_array_ref[i]=21.69ms
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v p=2 -v ns=2.65588e+07 'BEGIN { printf "%.*fms\n", p, ns / 1E6 }'
+ lat_array_ref[i]=26.56ms
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v p=2 -v ns=3.18769e+07 'BEGIN { printf "%.*fms\n", p, ns / 1E6 }'
+ lat_array_ref[i]=31.88ms
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v p=2 -v ns=7.02493e+07 'BEGIN { printf "%.*fms\n", p, ns / 1E6 }'
+ lat_array_ref[i]=70.25ms
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v p=2 -v ns=1.77932e+08 'BEGIN { printf "%.*fms\n", p, ns / 1E6 }'
+ lat_array_ref[i]=177.93ms
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v p=2 -v ns=2.46281e+08 'BEGIN { printf "%.*fms\n", p, ns / 1E6 }'
+ lat_array_ref[i]=246.28ms
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v p=2 -v ns=5.19394e+08 'BEGIN { printf "%.*fms\n", p, ns / 1E6 }'
+ lat_array_ref[i]=519.39ms
+ (( i++ ))
+ (( i < ROW_COUNT ))
+ echo '| File Size | BlockSize | nrfiles | Bandwidth in (MB/sec) | IOPs | IOPs Avg Latency (ms) |'
+ echo '|---|---|---|---|---|---|'
+ (( i = 0 ))
+ (( i < ROW_COUNT ))
+ echo '| 128K | 128K | 30 | 940.778 | 7.18K | 15.19ms |'
+ (( i++ ))
+ (( i < ROW_COUNT ))
+ echo '| 256K | 128K | 30 | 997.654 | 7.61K | 14.96ms |'
+ (( i++ ))
+ (( i < ROW_COUNT ))
+ echo '| 1MB | 1M | 30 | 4793.490 | 4.57K | 21.69ms |'
+ (( i++ ))
+ (( i < ROW_COUNT ))
+ echo '| 5MB | 1M | 20 | 5144.413 | 4.91K | 26.56ms |'
+ (( i++ ))
+ (( i < ROW_COUNT ))
+ echo '| 10MB | 1M | 20 | 5336.689 | 5.09K | 31.88ms |'
+ (( i++ ))
+ (( i < ROW_COUNT ))
+ echo '| 50MB | 1M | 20 | 4499.572 | 4.29K | 70.25ms |'
+ (( i++ ))
+ (( i < ROW_COUNT ))
+ echo '| 100MB | 1M | 10 | 4029.836 | 3.84K | 177.93ms |'
+ (( i++ ))
+ (( i < ROW_COUNT ))
+ echo '| 200MB | 1M | 10 | 3801.233 | 3.63K | 246.28ms |'
+ (( i++ ))
+ (( i < ROW_COUNT ))
+ echo '| 1GB | 1M | 10 | 2454.249 | 2.34K | 519.39ms |'
+ (( i++ ))
+ (( i < ROW_COUNT ))
+ echo ''
+ create_table 'Sequential Writes' /tmp/create_benchmark_tables.dKkjUd/gcsfuse-write-workload-benchmark write MB
+ local 'table_name=Sequential Writes'
+ local file=/tmp/create_benchmark_tables.dKkjUd/gcsfuse-write-workload-benchmark
+ local workflow_type=write
+ local bw_in=MB
+ echo '### Sequential Writes'
++ job_count /tmp/create_benchmark_tables.dKkjUd/gcsfuse-write-workload-benchmark_1.json
++ local file=/tmp/create_benchmark_tables.dKkjUd/gcsfuse-write-workload-benchmark_1.json
++ local count
+++ jq '.jobs | length' /tmp/create_benchmark_tables.dKkjUd/gcsfuse-write-workload-benchmark_1.json
++ count=5
++ [[ 5 -le 0 ]]
++ echo 5
+ ROW_COUNT=5
+ populate_all_columns /tmp/create_benchmark_tables.dKkjUd/gcsfuse-write-workload-benchmark write
+ local file=/tmp/create_benchmark_tables.dKkjUd/gcsfuse-write-workload-benchmark
+ local op_type=write
+ local lat_ns_op_type=write.lat_ns
+ populate_array_from_jq /tmp/create_benchmark_tables.dKkjUd/gcsfuse-write-workload-benchmark_1.json '.jobs[]?."job options"' '."global options"' bs bs
+ local file=/tmp/create_benchmark_tables.dKkjUd/gcsfuse-write-workload-benchmark_1.json
+ local 'jq_job_path_template=.jobs[]?."job options"'
+ local 'jq_global_path_template=."global options"'
+ local field_name=bs
+ local -n array_ref=bs
+ array_ref=()
+ local 'jq_job_query=.jobs[]?."job options"["bs"]?'
+ local 'jq_global_query=."global options"["bs"]?'
+ mapfile -t values
++ jq -r '.jobs[]?."job options"["bs"]?' /tmp/create_benchmark_tables.dKkjUd/gcsfuse-write-workload-benchmark_1.json
+ local i
+ for i in "${!values[@]}"
+ local value=16K
+ [[ 16K == \n\u\l\l ]]
+ [[ 16K == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=null
+ [[ null == \n\u\l\l ]]
++ jq -r '."global options"["bs"]?' /tmp/create_benchmark_tables.dKkjUd/gcsfuse-write-workload-benchmark_1.json
+ value=1M
+ [[ 1M == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=null
+ [[ null == \n\u\l\l ]]
++ jq -r '."global options"["bs"]?' /tmp/create_benchmark_tables.dKkjUd/gcsfuse-write-workload-benchmark_1.json
+ value=1M
+ [[ 1M == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=null
+ [[ null == \n\u\l\l ]]
++ jq -r '."global options"["bs"]?' /tmp/create_benchmark_tables.dKkjUd/gcsfuse-write-workload-benchmark_1.json
+ value=1M
+ [[ 1M == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=null
+ [[ null == \n\u\l\l ]]
++ jq -r '."global options"["bs"]?' /tmp/create_benchmark_tables.dKkjUd/gcsfuse-write-workload-benchmark_1.json
+ value=1M
+ [[ 1M == \n\u\l\l ]]
+ array_ref+=("$value")
+ [[ 5 -ne 5 ]]
+ populate_array_from_jq /tmp/create_benchmark_tables.dKkjUd/gcsfuse-write-workload-benchmark_1.json '.jobs[]?."job options"' '."global options"' filesize filesize
+ local file=/tmp/create_benchmark_tables.dKkjUd/gcsfuse-write-workload-benchmark_1.json
+ local 'jq_job_path_template=.jobs[]?."job options"'
+ local 'jq_global_path_template=."global options"'
+ local field_name=filesize
+ local -n array_ref=filesize
+ array_ref=()
+ local 'jq_job_query=.jobs[]?."job options"["filesize"]?'
+ local 'jq_global_query=."global options"["filesize"]?'
+ mapfile -t values
++ jq -r '.jobs[]?."job options"["filesize"]?' /tmp/create_benchmark_tables.dKkjUd/gcsfuse-write-workload-benchmark_1.json
+ local i
+ for i in "${!values[@]}"
+ local value=256K
+ [[ 256K == \n\u\l\l ]]
+ [[ 256K == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=1M
+ [[ 1M == \n\u\l\l ]]
+ [[ 1M == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=50M
+ [[ 50M == \n\u\l\l ]]
+ [[ 50M == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=100M
+ [[ 100M == \n\u\l\l ]]
+ [[ 100M == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=1G
+ [[ 1G == \n\u\l\l ]]
+ [[ 1G == \n\u\l\l ]]
+ array_ref+=("$value")
+ [[ 5 -ne 5 ]]
+ populate_array_from_jq /tmp/create_benchmark_tables.dKkjUd/gcsfuse-write-workload-benchmark_1.json '.jobs[]?."job options"' '."global options"' nrfiles nrfiles
+ local file=/tmp/create_benchmark_tables.dKkjUd/gcsfuse-write-workload-benchmark_1.json
+ local 'jq_job_path_template=.jobs[]?."job options"'
+ local 'jq_global_path_template=."global options"'
+ local field_name=nrfiles
+ local -n array_ref=nrfiles
+ array_ref=()
+ local 'jq_job_query=.jobs[]?."job options"["nrfiles"]?'
+ local 'jq_global_query=."global options"["nrfiles"]?'
+ mapfile -t values
++ jq -r '.jobs[]?."job options"["nrfiles"]?' /tmp/create_benchmark_tables.dKkjUd/gcsfuse-write-workload-benchmark_1.json
+ local i
+ for i in "${!values[@]}"
+ local value=30
+ [[ 30 == \n\u\l\l ]]
+ [[ 30 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=30
+ [[ 30 == \n\u\l\l ]]
+ [[ 30 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=20
+ [[ 20 == \n\u\l\l ]]
+ [[ 20 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=10
+ [[ 10 == \n\u\l\l ]]
+ [[ 10 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=2
+ [[ 2 == \n\u\l\l ]]
+ [[ 2 == \n\u\l\l ]]
+ array_ref+=("$value")
+ [[ 5 -ne 5 ]]
+ populate_avg_in_array_for_all_runs /tmp/create_benchmark_tables.dKkjUd/gcsfuse-write-workload-benchmark '.jobs[]?.write' '."global options"' bw_bytes bw_bytes
+ local file=/tmp/create_benchmark_tables.dKkjUd/gcsfuse-write-workload-benchmark
+ local 'jq_job_path_template=.jobs[]?.write'
+ local 'jq_global_path_template=."global options"'
+ local field_name=bw_bytes
+ local -n array_ref=bw_bytes
+ sum=()
+ local sum
++ seq 1 1
+ for i in $(seq 1 "$BENCHMARK_COUNT")
+ curr_arr=()
+ local curr_arr
+ local curr_file_name=/tmp/create_benchmark_tables.dKkjUd/gcsfuse-write-workload-benchmark_1.json
+ populate_array_from_jq /tmp/create_benchmark_tables.dKkjUd/gcsfuse-write-workload-benchmark_1.json '.jobs[]?.write' '."global options"' bw_bytes curr_arr
+ local file=/tmp/create_benchmark_tables.dKkjUd/gcsfuse-write-workload-benchmark_1.json
+ local 'jq_job_path_template=.jobs[]?.write'
+ local 'jq_global_path_template=."global options"'
+ local field_name=bw_bytes
+ local -n array_ref=curr_arr
+ array_ref=()
+ local 'jq_job_query=.jobs[]?.write["bw_bytes"]?'
+ local 'jq_global_query=."global options"["bw_bytes"]?'
+ mapfile -t values
++ jq -r '.jobs[]?.write["bw_bytes"]?' /tmp/create_benchmark_tables.dKkjUd/gcsfuse-write-workload-benchmark_1.json
+ local i
+ for i in "${!values[@]}"
+ local value=266748588
+ [[ 266748588 == \n\u\l\l ]]
+ [[ 266748588 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=924971215
+ [[ 924971215 == \n\u\l\l ]]
+ [[ 924971215 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=3697981988
+ [[ 3697981988 == \n\u\l\l ]]
+ [[ 3697981988 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=3873112327
+ [[ 3873112327 == \n\u\l\l ]]
+ [[ 3873112327 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=2221056132
+ [[ 2221056132 == \n\u\l\l ]]
+ [[ 2221056132 == \n\u\l\l ]]
+ array_ref+=("$value")
+ [[ 5 -ne 5 ]]
+ [[ 1 -eq 1 ]]
+ sum=("${curr_arr[@]}")
+ (( i = 0 ))
+ (( i < ROW_COUNT ))
++ awk -v s=266748588 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=266748588
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=924971215 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=924971215
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=3697981988 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=3697981988
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=3873112327 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=3873112327
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=2221056132 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=2221056132
+ (( i++ ))
+ (( i < ROW_COUNT ))
+ populate_avg_in_array_for_all_runs /tmp/create_benchmark_tables.dKkjUd/gcsfuse-write-workload-benchmark '.jobs[]?.write' '."global options"' iops iops
+ local file=/tmp/create_benchmark_tables.dKkjUd/gcsfuse-write-workload-benchmark
+ local 'jq_job_path_template=.jobs[]?.write'
+ local 'jq_global_path_template=."global options"'
+ local field_name=iops
+ local -n array_ref=iops
+ sum=()
+ local sum
++ seq 1 1
+ for i in $(seq 1 "$BENCHMARK_COUNT")
+ curr_arr=()
+ local curr_arr
+ local curr_file_name=/tmp/create_benchmark_tables.dKkjUd/gcsfuse-write-workload-benchmark_1.json
+ populate_array_from_jq /tmp/create_benchmark_tables.dKkjUd/gcsfuse-write-workload-benchmark_1.json '.jobs[]?.write' '."global options"' iops curr_arr
+ local file=/tmp/create_benchmark_tables.dKkjUd/gcsfuse-write-workload-benchmark_1.json
+ local 'jq_job_path_template=.jobs[]?.write'
+ local 'jq_global_path_template=."global options"'
+ local field_name=iops
+ local -n array_ref=curr_arr
+ array_ref=()
+ local 'jq_job_query=.jobs[]?.write["iops"]?'
+ local 'jq_global_query=."global options"["iops"]?'
+ mapfile -t values
++ jq -r '.jobs[]?.write["iops"]?' /tmp/create_benchmark_tables.dKkjUd/gcsfuse-write-workload-benchmark_1.json
+ local i
+ for i in "${!values[@]}"
+ local value=16281.041793
+ [[ 16281.041793 == \n\u\l\l ]]
+ [[ 16281.041793 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=882.121292
+ [[ 882.121292 == \n\u\l\l ]]
+ [[ 882.121292 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=3526.670445
+ [[ 3526.670445 == \n\u\l\l ]]
+ [[ 3526.670445 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=3693.687751
+ [[ 3693.687751 == \n\u\l\l ]]
+ [[ 3693.687751 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=2118.164189
+ [[ 2118.164189 == \n\u\l\l ]]
+ [[ 2118.164189 == \n\u\l\l ]]
+ array_ref+=("$value")
+ [[ 5 -ne 5 ]]
+ [[ 1 -eq 1 ]]
+ sum=("${curr_arr[@]}")
+ (( i = 0 ))
+ (( i < ROW_COUNT ))
++ awk -v s=16281.041793 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=16281
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=882.121292 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=882.121
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=3526.670445 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=3526.67
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=3693.687751 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=3693.69
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=2118.164189 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=2118.16
+ (( i++ ))
+ (( i < ROW_COUNT ))
+ populate_avg_in_array_for_all_runs /tmp/create_benchmark_tables.dKkjUd/gcsfuse-write-workload-benchmark '.jobs[]?.write.lat_ns' '."global options"' mean lat_mean
+ local file=/tmp/create_benchmark_tables.dKkjUd/gcsfuse-write-workload-benchmark
+ local 'jq_job_path_template=.jobs[]?.write.lat_ns'
+ local 'jq_global_path_template=."global options"'
+ local field_name=mean
+ local -n array_ref=lat_mean
+ sum=()
+ local sum
++ seq 1 1
+ for i in $(seq 1 "$BENCHMARK_COUNT")
+ curr_arr=()
+ local curr_arr
+ local curr_file_name=/tmp/create_benchmark_tables.dKkjUd/gcsfuse-write-workload-benchmark_1.json
+ populate_array_from_jq /tmp/create_benchmark_tables.dKkjUd/gcsfuse-write-workload-benchmark_1.json '.jobs[]?.write.lat_ns' '."global options"' mean curr_arr
+ local file=/tmp/create_benchmark_tables.dKkjUd/gcsfuse-write-workload-benchmark_1.json
+ local 'jq_job_path_template=.jobs[]?.write.lat_ns'
+ local 'jq_global_path_template=."global options"'
+ local field_name=mean
+ local -n array_ref=curr_arr
+ array_ref=()
+ local 'jq_job_query=.jobs[]?.write.lat_ns["mean"]?'
+ local 'jq_global_query=."global options"["mean"]?'
+ mapfile -t values
++ jq -r '.jobs[]?.write.lat_ns["mean"]?' /tmp/create_benchmark_tables.dKkjUd/gcsfuse-write-workload-benchmark_1.json
+ local i
+ for i in "${!values[@]}"
+ local value=2911179.528144
+ [[ 2911179.528144 == \n\u\l\l ]]
+ [[ 2911179.528144 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=54903393.000595
+ [[ 54903393.000595 == \n\u\l\l ]]
+ [[ 54903393.000595 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=15257559.505571
+ [[ 15257559.505571 == \n\u\l\l ]]
+ [[ 15257559.505571 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=16826059.184429
+ [[ 16826059.184429 == \n\u\l\l ]]
+ [[ 16826059.184429 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=41953367.269575
+ [[ 41953367.269575 == \n\u\l\l ]]
+ [[ 41953367.269575 == \n\u\l\l ]]
+ array_ref+=("$value")
+ [[ 5 -ne 5 ]]
+ [[ 1 -eq 1 ]]
+ sum=("${curr_arr[@]}")
+ (( i = 0 ))
+ (( i < ROW_COUNT ))
++ awk -v s=2911179.528144 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=2.91118e+06
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=54903393.000595 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=5.49034e+07
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=15257559.505571 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=1.52576e+07
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=16826059.184429 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=1.68261e+07
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=41953367.269575 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=4.19534e+07
+ (( i++ ))
+ (( i < ROW_COUNT ))
+ convert_bytes_to MB
+ local division=1000000
+ local precision=3
+ (( i = 0 ))
+ (( i < ROW_COUNT ))
++ awk -v prec=3 -v div=1000000 -v bval=266748588 'BEGIN { printf "%.*f\n", prec, bval / div }'
+ bw_bytes[i]=266.749
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v prec=3 -v div=1000000 -v bval=924971215 'BEGIN { printf "%.*f\n", prec, bval / div }'
+ bw_bytes[i]=924.971
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v prec=3 -v div=1000000 -v bval=3697981988 'BEGIN { printf "%.*f\n", prec, bval / div }'
+ bw_bytes[i]=3697.982
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v prec=3 -v div=1000000 -v bval=3873112327 'BEGIN { printf "%.*f\n", prec, bval / div }'
+ bw_bytes[i]=3873.112
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v prec=3 -v div=1000000 -v bval=2221056132 'BEGIN { printf "%.*f\n", prec, bval / div }'
+ bw_bytes[i]=2221.056
+ (( i++ ))
+ (( i < ROW_COUNT ))
+ format_iops_to_kilo
+ (( i = 0 ))
+ (( i < ROW_COUNT ))
++ awk -v n=16281 'BEGIN { printf "%.2fK\n", n / 1000 }'
+ iops[i]=16.28K
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v n=882.121 'BEGIN { printf "%.2fK\n", n / 1000 }'
+ iops[i]=0.88K
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v n=3526.67 'BEGIN { printf "%.2fK\n", n / 1000 }'
+ iops[i]=3.53K
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v n=3693.69 'BEGIN { printf "%.2fK\n", n / 1000 }'
+ iops[i]=3.69K
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v n=2118.16 'BEGIN { printf "%.2fK\n", n / 1000 }'
+ iops[i]=2.12K
+ (( i++ ))
+ (( i < ROW_COUNT ))
+ convert_lat_mean_ns_to_ms lat_mean
+ local -n lat_array_ref=lat_mean
+ local precision=2
+ (( i = 0 ))
+ (( i < ROW_COUNT ))
++ awk -v p=2 -v ns=2.91118e+06 'BEGIN { printf "%.*fms\n", p, ns / 1E6 }'
+ lat_array_ref[i]=2.91ms
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v p=2 -v ns=5.49034e+07 'BEGIN { printf "%.*fms\n", p, ns / 1E6 }'
+ lat_array_ref[i]=54.90ms
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v p=2 -v ns=1.52576e+07 'BEGIN { printf "%.*fms\n", p, ns / 1E6 }'
+ lat_array_ref[i]=15.26ms
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v p=2 -v ns=1.68261e+07 'BEGIN { printf "%.*fms\n", p, ns / 1E6 }'
+ lat_array_ref[i]=16.83ms
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v p=2 -v ns=4.19534e+07 'BEGIN { printf "%.*fms\n", p, ns / 1E6 }'
+ lat_array_ref[i]=41.95ms
+ (( i++ ))
+ (( i < ROW_COUNT ))
+ echo '| File Size | BlockSize | nrfiles | Bandwidth in (MB/sec) | IOPs | IOPs Avg Latency (ms) |'
+ echo '|---|---|---|---|---|---|'
+ (( i = 0 ))
+ (( i < ROW_COUNT ))
+ echo '| 256K | 16K | 30 | 266.749 | 16.28K | 2.91ms |'
+ (( i++ ))
+ (( i < ROW_COUNT ))
+ echo '| 1M | 1M | 30 | 924.971 | 0.88K | 54.90ms |'
+ (( i++ ))
+ (( i < ROW_COUNT ))
+ echo '| 50M | 1M | 20 | 3697.982 | 3.53K | 15.26ms |'
+ (( i++ ))
+ (( i < ROW_COUNT ))
+ echo '| 100M | 1M | 10 | 3873.112 | 3.69K | 16.83ms |'
+ (( i++ ))
+ (( i < ROW_COUNT ))
+ echo '| 1G | 1M | 2 | 2221.056 | 2.12K | 41.95ms |'
+ (( i++ ))
+ (( i < ROW_COUNT ))
+ echo ''
+ gcloud storage cp /tmp/create_benchmark_tables.dKkjUd/tables.md gs://gcsfuse-release-benchmarks-results/enable_read_manager_flag/c4-standard-96/
Copying file:///tmp/create_benchmark_tables.dKkjUd/tables.md to gs://gcsfuse-release-benchmarks-results/enable_read_manager_flag/c4-standard-96/tables.md
  
..
+ echo 'Benchmark table successfully created and uploaded to gs://gcsfuse-release-benchmarks-results/enable_read_manager_flag/c4-standard-96/tables.md'
Benchmark table successfully created and uploaded to gs://gcsfuse-release-benchmarks-results/enable_read_manager_flag/c4-standard-96/tables.md
+ rm -rf /tmp/create_benchmark_tables.dKkjUd
+ ./create_benchmark_tables.sh enable_read_manager_flag us-south1 n2-standard-96 'gVNIC+ tier_1 networking (100Gbps)' 'SSD persistent disk' 1
+ '[' 6 -ne 6 ']'
++ mktemp -d -t create_benchmark_tables.XXXXXX
+ TMP_DIR=/tmp/create_benchmark_tables.B0pnL6
+ trap 'rm -rf "$TMP_DIR"' EXIT
+ TABLES_FILE=/tmp/create_benchmark_tables.B0pnL6/tables.md
+ RESULTS_BUCKET_NAME=gcsfuse-release-benchmarks-results
+ GCSFUSE_VERSION=enable_read_manager_flag
+ REGION=us-south1
+ MACHINE_TYPE=n2-standard-96
+ NETWORKING='gVNIC+ tier_1 networking (100Gbps)'
+ DISK_TYPE='SSD persistent disk'
+ BENCHMARK_COUNT=1
+ RANDOM_READ_RES_BASENAME=gcsfuse-random-read-workload-benchmark
+ SEQ_READ_RES_BASENAME=gcsfuse-sequential-read-workload-benchmark
+ WRITE_RES_BASENAME=gcsfuse-write-workload-benchmark
+ JSON_FILES_BASENAMES=("$RANDOM_READ_RES_BASENAME" "$SEQ_READ_RES_BASENAME" "$WRITE_RES_BASENAME")
+ gcloud storage objects describe gs://gcsfuse-release-benchmarks-results/enable_read_manager_flag/n2-standard-96/success.txt
+ echo 'Found the success.txt file in the bucket.'
Found the success.txt file in the bucket.
+ for basename in "${JSON_FILES_BASENAMES[@]}"
++ seq 1 1
+ for i in $(seq 1 "$BENCHMARK_COUNT")
+ curr_filename=gcsfuse-random-read-workload-benchmark_1.json
+ gcloud storage cp gs://gcsfuse-release-benchmarks-results/enable_read_manager_flag/n2-standard-96/gcsfuse-random-read-workload-benchmark_1.json /tmp/create_benchmark_tables.B0pnL6/gcsfuse-random-read-workload-benchmark_1.json
Copying gs://gcsfuse-release-benchmarks-results/enable_read_manager_flag/n2-standard-96/gcsfuse-random-read-workload-benchmark_1.json to file:///tmp/create_benchmark_tables.B0pnL6/gcsfuse-random-read-workload-benchmark_1.json
  
..
+ sed -i '/^note:/d' /tmp/create_benchmark_tables.B0pnL6/gcsfuse-random-read-workload-benchmark_1.json
+ for basename in "${JSON_FILES_BASENAMES[@]}"
++ seq 1 1
+ for i in $(seq 1 "$BENCHMARK_COUNT")
+ curr_filename=gcsfuse-sequential-read-workload-benchmark_1.json
+ gcloud storage cp gs://gcsfuse-release-benchmarks-results/enable_read_manager_flag/n2-standard-96/gcsfuse-sequential-read-workload-benchmark_1.json /tmp/create_benchmark_tables.B0pnL6/gcsfuse-sequential-read-workload-benchmark_1.json
Copying gs://gcsfuse-release-benchmarks-results/enable_read_manager_flag/n2-standard-96/gcsfuse-sequential-read-workload-benchmark_1.json to file:///tmp/create_benchmark_tables.B0pnL6/gcsfuse-sequential-read-workload-benchmark_1.json
  
..
+ sed -i '/^note:/d' /tmp/create_benchmark_tables.B0pnL6/gcsfuse-sequential-read-workload-benchmark_1.json
+ for basename in "${JSON_FILES_BASENAMES[@]}"
++ seq 1 1
+ for i in $(seq 1 "$BENCHMARK_COUNT")
+ curr_filename=gcsfuse-write-workload-benchmark_1.json
+ gcloud storage cp gs://gcsfuse-release-benchmarks-results/enable_read_manager_flag/n2-standard-96/gcsfuse-write-workload-benchmark_1.json /tmp/create_benchmark_tables.B0pnL6/gcsfuse-write-workload-benchmark_1.json
Copying gs://gcsfuse-release-benchmarks-results/enable_read_manager_flag/n2-standard-96/gcsfuse-write-workload-benchmark_1.json to file:///tmp/create_benchmark_tables.B0pnL6/gcsfuse-write-workload-benchmark_1.json
  
...
+ sed -i '/^note:/d' /tmp/create_benchmark_tables.B0pnL6/gcsfuse-write-workload-benchmark_1.json
+ RANDOM_READ_RES=/tmp/create_benchmark_tables.B0pnL6/gcsfuse-random-read-workload-benchmark
+ SEQ_READ_RES=/tmp/create_benchmark_tables.B0pnL6/gcsfuse-sequential-read-workload-benchmark
+ WRITE_RES=/tmp/create_benchmark_tables.B0pnL6/gcsfuse-write-workload-benchmark
+ ROW_COUNT=0
+ declare -a filesize bw_bytes nrfiles iops lat_mean bs
+ bytes_in=(['MB']='1000000' ['GB']='1000000000')
+ declare -A bytes_in
+ create_tables_markdown_content
+ echo '## GCSFuse Benchmarking on n2 machine-type'
+ echo '* VM Type: n2-standard-96'
+ echo '* VM location: us-south1'
+ echo '* Networking: gVNIC+ tier_1 networking (100Gbps)'
+ echo '* Disk Type: SSD persistent disk'
+ echo '* GCS Bucket location: us-south1'
+ echo ''
+ create_table 'Sequential Reads' /tmp/create_benchmark_tables.B0pnL6/gcsfuse-sequential-read-workload-benchmark read GB
+ local 'table_name=Sequential Reads'
+ local file=/tmp/create_benchmark_tables.B0pnL6/gcsfuse-sequential-read-workload-benchmark
+ local workflow_type=read
+ local bw_in=GB
+ echo '### Sequential Reads'
++ job_count /tmp/create_benchmark_tables.B0pnL6/gcsfuse-sequential-read-workload-benchmark_1.json
++ local file=/tmp/create_benchmark_tables.B0pnL6/gcsfuse-sequential-read-workload-benchmark_1.json
++ local count
+++ jq '.jobs | length' /tmp/create_benchmark_tables.B0pnL6/gcsfuse-sequential-read-workload-benchmark_1.json
++ count=9
++ [[ 9 -le 0 ]]
++ echo 9
+ ROW_COUNT=9
+ populate_all_columns /tmp/create_benchmark_tables.B0pnL6/gcsfuse-sequential-read-workload-benchmark read
+ local file=/tmp/create_benchmark_tables.B0pnL6/gcsfuse-sequential-read-workload-benchmark
+ local op_type=read
+ local lat_ns_op_type=read.lat_ns
+ populate_array_from_jq /tmp/create_benchmark_tables.B0pnL6/gcsfuse-sequential-read-workload-benchmark_1.json '.jobs[]?."job options"' '."global options"' bs bs
+ local file=/tmp/create_benchmark_tables.B0pnL6/gcsfuse-sequential-read-workload-benchmark_1.json
+ local 'jq_job_path_template=.jobs[]?."job options"'
+ local 'jq_global_path_template=."global options"'
+ local field_name=bs
+ local -n array_ref=bs
+ array_ref=()
+ local 'jq_job_query=.jobs[]?."job options"["bs"]?'
+ local 'jq_global_query=."global options"["bs"]?'
+ mapfile -t values
++ jq -r '.jobs[]?."job options"["bs"]?' /tmp/create_benchmark_tables.B0pnL6/gcsfuse-sequential-read-workload-benchmark_1.json
+ local i
+ for i in "${!values[@]}"
+ local value=128K
+ [[ 128K == \n\u\l\l ]]
+ [[ 128K == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=128K
+ [[ 128K == \n\u\l\l ]]
+ [[ 128K == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=1M
+ [[ 1M == \n\u\l\l ]]
+ [[ 1M == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=1M
+ [[ 1M == \n\u\l\l ]]
+ [[ 1M == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=1M
+ [[ 1M == \n\u\l\l ]]
+ [[ 1M == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=1M
+ [[ 1M == \n\u\l\l ]]
+ [[ 1M == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=1M
+ [[ 1M == \n\u\l\l ]]
+ [[ 1M == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=1M
+ [[ 1M == \n\u\l\l ]]
+ [[ 1M == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=1M
+ [[ 1M == \n\u\l\l ]]
+ [[ 1M == \n\u\l\l ]]
+ array_ref+=("$value")
+ [[ 9 -ne 9 ]]
+ populate_array_from_jq /tmp/create_benchmark_tables.B0pnL6/gcsfuse-sequential-read-workload-benchmark_1.json '.jobs[]?."job options"' '."global options"' filesize filesize
+ local file=/tmp/create_benchmark_tables.B0pnL6/gcsfuse-sequential-read-workload-benchmark_1.json
+ local 'jq_job_path_template=.jobs[]?."job options"'
+ local 'jq_global_path_template=."global options"'
+ local field_name=filesize
+ local -n array_ref=filesize
+ array_ref=()
+ local 'jq_job_query=.jobs[]?."job options"["filesize"]?'
+ local 'jq_global_query=."global options"["filesize"]?'
+ mapfile -t values
++ jq -r '.jobs[]?."job options"["filesize"]?' /tmp/create_benchmark_tables.B0pnL6/gcsfuse-sequential-read-workload-benchmark_1.json
+ local i
+ for i in "${!values[@]}"
+ local value=128K
+ [[ 128K == \n\u\l\l ]]
+ [[ 128K == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=256K
+ [[ 256K == \n\u\l\l ]]
+ [[ 256K == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=1MB
+ [[ 1MB == \n\u\l\l ]]
+ [[ 1MB == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=5MB
+ [[ 5MB == \n\u\l\l ]]
+ [[ 5MB == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=10MB
+ [[ 10MB == \n\u\l\l ]]
+ [[ 10MB == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=50MB
+ [[ 50MB == \n\u\l\l ]]
+ [[ 50MB == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=100MB
+ [[ 100MB == \n\u\l\l ]]
+ [[ 100MB == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=200MB
+ [[ 200MB == \n\u\l\l ]]
+ [[ 200MB == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=1GB
+ [[ 1GB == \n\u\l\l ]]
+ [[ 1GB == \n\u\l\l ]]
+ array_ref+=("$value")
+ [[ 9 -ne 9 ]]
+ populate_array_from_jq /tmp/create_benchmark_tables.B0pnL6/gcsfuse-sequential-read-workload-benchmark_1.json '.jobs[]?."job options"' '."global options"' nrfiles nrfiles
+ local file=/tmp/create_benchmark_tables.B0pnL6/gcsfuse-sequential-read-workload-benchmark_1.json
+ local 'jq_job_path_template=.jobs[]?."job options"'
+ local 'jq_global_path_template=."global options"'
+ local field_name=nrfiles
+ local -n array_ref=nrfiles
+ array_ref=()
+ local 'jq_job_query=.jobs[]?."job options"["nrfiles"]?'
+ local 'jq_global_query=."global options"["nrfiles"]?'
+ mapfile -t values
++ jq -r '.jobs[]?."job options"["nrfiles"]?' /tmp/create_benchmark_tables.B0pnL6/gcsfuse-sequential-read-workload-benchmark_1.json
+ local i
+ for i in "${!values[@]}"
+ local value=30
+ [[ 30 == \n\u\l\l ]]
+ [[ 30 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=30
+ [[ 30 == \n\u\l\l ]]
+ [[ 30 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=30
+ [[ 30 == \n\u\l\l ]]
+ [[ 30 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=20
+ [[ 20 == \n\u\l\l ]]
+ [[ 20 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=20
+ [[ 20 == \n\u\l\l ]]
+ [[ 20 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=20
+ [[ 20 == \n\u\l\l ]]
+ [[ 20 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=10
+ [[ 10 == \n\u\l\l ]]
+ [[ 10 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=10
+ [[ 10 == \n\u\l\l ]]
+ [[ 10 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=10
+ [[ 10 == \n\u\l\l ]]
+ [[ 10 == \n\u\l\l ]]
+ array_ref+=("$value")
+ [[ 9 -ne 9 ]]
+ populate_avg_in_array_for_all_runs /tmp/create_benchmark_tables.B0pnL6/gcsfuse-sequential-read-workload-benchmark '.jobs[]?.read' '."global options"' bw_bytes bw_bytes
+ local file=/tmp/create_benchmark_tables.B0pnL6/gcsfuse-sequential-read-workload-benchmark
+ local 'jq_job_path_template=.jobs[]?.read'
+ local 'jq_global_path_template=."global options"'
+ local field_name=bw_bytes
+ local -n array_ref=bw_bytes
+ sum=()
+ local sum
++ seq 1 1
+ for i in $(seq 1 "$BENCHMARK_COUNT")
+ curr_arr=()
+ local curr_arr
+ local curr_file_name=/tmp/create_benchmark_tables.B0pnL6/gcsfuse-sequential-read-workload-benchmark_1.json
+ populate_array_from_jq /tmp/create_benchmark_tables.B0pnL6/gcsfuse-sequential-read-workload-benchmark_1.json '.jobs[]?.read' '."global options"' bw_bytes curr_arr
+ local file=/tmp/create_benchmark_tables.B0pnL6/gcsfuse-sequential-read-workload-benchmark_1.json
+ local 'jq_job_path_template=.jobs[]?.read'
+ local 'jq_global_path_template=."global options"'
+ local field_name=bw_bytes
+ local -n array_ref=curr_arr
+ array_ref=()
+ local 'jq_job_query=.jobs[]?.read["bw_bytes"]?'
+ local 'jq_global_query=."global options"["bw_bytes"]?'
+ mapfile -t values
++ jq -r '.jobs[]?.read["bw_bytes"]?' /tmp/create_benchmark_tables.B0pnL6/gcsfuse-sequential-read-workload-benchmark_1.json
+ local i
+ for i in "${!values[@]}"
+ local value=756866887
+ [[ 756866887 == \n\u\l\l ]]
+ [[ 756866887 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=1440104377
+ [[ 1440104377 == \n\u\l\l ]]
+ [[ 1440104377 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=4198677622
+ [[ 4198677622 == \n\u\l\l ]]
+ [[ 4198677622 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=6493358877
+ [[ 6493358877 == \n\u\l\l ]]
+ [[ 6493358877 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=7165922477
+ [[ 7165922477 == \n\u\l\l ]]
+ [[ 7165922477 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=7452814037
+ [[ 7452814037 == \n\u\l\l ]]
+ [[ 7452814037 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=7219500188
+ [[ 7219500188 == \n\u\l\l ]]
+ [[ 7219500188 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=6729898362
+ [[ 6729898362 == \n\u\l\l ]]
+ [[ 6729898362 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=7605876750
+ [[ 7605876750 == \n\u\l\l ]]
+ [[ 7605876750 == \n\u\l\l ]]
+ array_ref+=("$value")
+ [[ 9 -ne 9 ]]
+ [[ 1 -eq 1 ]]
+ sum=("${curr_arr[@]}")
+ (( i = 0 ))
+ (( i < ROW_COUNT ))
++ awk -v s=756866887 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=756866887
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=1440104377 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=1440104377
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=4198677622 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=4198677622
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=6493358877 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=6493358877
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=7165922477 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=7165922477
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=7452814037 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=7452814037
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=7219500188 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=7219500188
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=6729898362 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=6729898362
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=7605876750 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=7605876750
+ (( i++ ))
+ (( i < ROW_COUNT ))
+ populate_avg_in_array_for_all_runs /tmp/create_benchmark_tables.B0pnL6/gcsfuse-sequential-read-workload-benchmark '.jobs[]?.read' '."global options"' iops iops
+ local file=/tmp/create_benchmark_tables.B0pnL6/gcsfuse-sequential-read-workload-benchmark
+ local 'jq_job_path_template=.jobs[]?.read'
+ local 'jq_global_path_template=."global options"'
+ local field_name=iops
+ local -n array_ref=iops
+ sum=()
+ local sum
++ seq 1 1
+ for i in $(seq 1 "$BENCHMARK_COUNT")
+ curr_arr=()
+ local curr_arr
+ local curr_file_name=/tmp/create_benchmark_tables.B0pnL6/gcsfuse-sequential-read-workload-benchmark_1.json
+ populate_array_from_jq /tmp/create_benchmark_tables.B0pnL6/gcsfuse-sequential-read-workload-benchmark_1.json '.jobs[]?.read' '."global options"' iops curr_arr
+ local file=/tmp/create_benchmark_tables.B0pnL6/gcsfuse-sequential-read-workload-benchmark_1.json
+ local 'jq_job_path_template=.jobs[]?.read'
+ local 'jq_global_path_template=."global options"'
+ local field_name=iops
+ local -n array_ref=curr_arr
+ array_ref=()
+ local 'jq_job_query=.jobs[]?.read["iops"]?'
+ local 'jq_global_query=."global options"["iops"]?'
+ mapfile -t values
++ jq -r '.jobs[]?.read["iops"]?' /tmp/create_benchmark_tables.B0pnL6/gcsfuse-sequential-read-workload-benchmark_1.json
+ local i
+ for i in "${!values[@]}"
+ local value=5774.436090
+ [[ 5774.436090 == \n\u\l\l ]]
+ [[ 5774.436090 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=10987.124464
+ [[ 10987.124464 == \n\u\l\l ]]
+ [[ 10987.124464 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=4004.171011
+ [[ 4004.171011 == \n\u\l\l ]]
+ [[ 4004.171011 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=6192.549589
+ [[ 6192.549589 == \n\u\l\l ]]
+ [[ 6192.549589 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=6833.956220
+ [[ 6833.956220 == \n\u\l\l ]]
+ [[ 6833.956220 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=7107.557332
+ [[ 7107.557332 == \n\u\l\l ]]
+ [[ 7107.557332 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=6885.051907
+ [[ 6885.051907 == \n\u\l\l ]]
+ [[ 6885.051907 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=6418.131221
+ [[ 6418.131221 == \n\u\l\l ]]
+ [[ 6418.131221 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=7253.529311
+ [[ 7253.529311 == \n\u\l\l ]]
+ [[ 7253.529311 == \n\u\l\l ]]
+ array_ref+=("$value")
+ [[ 9 -ne 9 ]]
+ [[ 1 -eq 1 ]]
+ sum=("${curr_arr[@]}")
+ (( i = 0 ))
+ (( i < ROW_COUNT ))
++ awk -v s=5774.436090 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=5774.44
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=10987.124464 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=10987.1
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=4004.171011 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=4004.17
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=6192.549589 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=6192.55
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=6833.956220 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=6833.96
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=7107.557332 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=7107.56
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=6885.051907 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=6885.05
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=6418.131221 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=6418.13
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=7253.529311 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=7253.53
+ (( i++ ))
+ (( i < ROW_COUNT ))
+ populate_avg_in_array_for_all_runs /tmp/create_benchmark_tables.B0pnL6/gcsfuse-sequential-read-workload-benchmark '.jobs[]?.read.lat_ns' '."global options"' mean lat_mean
+ local file=/tmp/create_benchmark_tables.B0pnL6/gcsfuse-sequential-read-workload-benchmark
+ local 'jq_job_path_template=.jobs[]?.read.lat_ns'
+ local 'jq_global_path_template=."global options"'
+ local field_name=mean
+ local -n array_ref=lat_mean
+ sum=()
+ local sum
++ seq 1 1
+ for i in $(seq 1 "$BENCHMARK_COUNT")
+ curr_arr=()
+ local curr_arr
+ local curr_file_name=/tmp/create_benchmark_tables.B0pnL6/gcsfuse-sequential-read-workload-benchmark_1.json
+ populate_array_from_jq /tmp/create_benchmark_tables.B0pnL6/gcsfuse-sequential-read-workload-benchmark_1.json '.jobs[]?.read.lat_ns' '."global options"' mean curr_arr
+ local file=/tmp/create_benchmark_tables.B0pnL6/gcsfuse-sequential-read-workload-benchmark_1.json
+ local 'jq_job_path_template=.jobs[]?.read.lat_ns'
+ local 'jq_global_path_template=."global options"'
+ local field_name=mean
+ local -n array_ref=curr_arr
+ array_ref=()
+ local 'jq_job_query=.jobs[]?.read.lat_ns["mean"]?'
+ local 'jq_global_query=."global options"["mean"]?'
+ mapfile -t values
++ jq -r '.jobs[]?.read.lat_ns["mean"]?' /tmp/create_benchmark_tables.B0pnL6/gcsfuse-sequential-read-workload-benchmark_1.json
+ local i
+ for i in "${!values[@]}"
+ local value=18111179.977604
+ [[ 18111179.977604 == \n\u\l\l ]]
+ [[ 18111179.977604 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=9404520.215365
+ [[ 9404520.215365 == \n\u\l\l ]]
+ [[ 9404520.215365 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=23583259.669271
+ [[ 23583259.669271 == \n\u\l\l ]]
+ [[ 23583259.669271 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=18886248.666016
+ [[ 18886248.666016 == \n\u\l\l ]]
+ [[ 18886248.666016 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=20684226.727656
+ [[ 20684226.727656 == \n\u\l\l ]]
+ [[ 20684226.727656 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=33122880.997672
+ [[ 33122880.997672 == \n\u\l\l ]]
+ [[ 33122880.997672 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=76116554.188688
+ [[ 76116554.188688 == \n\u\l\l ]]
+ [[ 76116554.188688 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=88506741.996473
+ [[ 88506741.996473 == \n\u\l\l ]]
+ [[ 88506741.996473 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=138893657.255866
+ [[ 138893657.255866 == \n\u\l\l ]]
+ [[ 138893657.255866 == \n\u\l\l ]]
+ array_ref+=("$value")
+ [[ 9 -ne 9 ]]
+ [[ 1 -eq 1 ]]
+ sum=("${curr_arr[@]}")
+ (( i = 0 ))
+ (( i < ROW_COUNT ))
++ awk -v s=18111179.977604 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=1.81112e+07
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=9404520.215365 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=9.40452e+06
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=23583259.669271 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=2.35833e+07
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=18886248.666016 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=1.88862e+07
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=20684226.727656 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=2.06842e+07
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=33122880.997672 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=3.31229e+07
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=76116554.188688 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=7.61166e+07
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=88506741.996473 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=8.85067e+07
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=138893657.255866 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=1.38894e+08
+ (( i++ ))
+ (( i < ROW_COUNT ))
+ convert_bytes_to GB
+ local division=1000000000
+ local precision=3
+ (( i = 0 ))
+ (( i < ROW_COUNT ))
++ awk -v prec=3 -v div=1000000000 -v bval=756866887 'BEGIN { printf "%.*f\n", prec, bval / div }'
+ bw_bytes[i]=0.757
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v prec=3 -v div=1000000000 -v bval=1440104377 'BEGIN { printf "%.*f\n", prec, bval / div }'
+ bw_bytes[i]=1.440
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v prec=3 -v div=1000000000 -v bval=4198677622 'BEGIN { printf "%.*f\n", prec, bval / div }'
+ bw_bytes[i]=4.199
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v prec=3 -v div=1000000000 -v bval=6493358877 'BEGIN { printf "%.*f\n", prec, bval / div }'
+ bw_bytes[i]=6.493
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v prec=3 -v div=1000000000 -v bval=7165922477 'BEGIN { printf "%.*f\n", prec, bval / div }'
+ bw_bytes[i]=7.166
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v prec=3 -v div=1000000000 -v bval=7452814037 'BEGIN { printf "%.*f\n", prec, bval / div }'
+ bw_bytes[i]=7.453
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v prec=3 -v div=1000000000 -v bval=7219500188 'BEGIN { printf "%.*f\n", prec, bval / div }'
+ bw_bytes[i]=7.220
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v prec=3 -v div=1000000000 -v bval=6729898362 'BEGIN { printf "%.*f\n", prec, bval / div }'
+ bw_bytes[i]=6.730
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v prec=3 -v div=1000000000 -v bval=7605876750 'BEGIN { printf "%.*f\n", prec, bval / div }'
+ bw_bytes[i]=7.606
+ (( i++ ))
+ (( i < ROW_COUNT ))
+ format_iops_to_kilo
+ (( i = 0 ))
+ (( i < ROW_COUNT ))
++ awk -v n=5774.44 'BEGIN { printf "%.2fK\n", n / 1000 }'
+ iops[i]=5.77K
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v n=10987.1 'BEGIN { printf "%.2fK\n", n / 1000 }'
+ iops[i]=10.99K
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v n=4004.17 'BEGIN { printf "%.2fK\n", n / 1000 }'
+ iops[i]=4.00K
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v n=6192.55 'BEGIN { printf "%.2fK\n", n / 1000 }'
+ iops[i]=6.19K
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v n=6833.96 'BEGIN { printf "%.2fK\n", n / 1000 }'
+ iops[i]=6.83K
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v n=7107.56 'BEGIN { printf "%.2fK\n", n / 1000 }'
+ iops[i]=7.11K
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v n=6885.05 'BEGIN { printf "%.2fK\n", n / 1000 }'
+ iops[i]=6.89K
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v n=6418.13 'BEGIN { printf "%.2fK\n", n / 1000 }'
+ iops[i]=6.42K
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v n=7253.53 'BEGIN { printf "%.2fK\n", n / 1000 }'
+ iops[i]=7.25K
+ (( i++ ))
+ (( i < ROW_COUNT ))
+ convert_lat_mean_ns_to_ms lat_mean
+ local -n lat_array_ref=lat_mean
+ local precision=2
+ (( i = 0 ))
+ (( i < ROW_COUNT ))
++ awk -v p=2 -v ns=1.81112e+07 'BEGIN { printf "%.*fms\n", p, ns / 1E6 }'
+ lat_array_ref[i]=18.11ms
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v p=2 -v ns=9.40452e+06 'BEGIN { printf "%.*fms\n", p, ns / 1E6 }'
+ lat_array_ref[i]=9.40ms
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v p=2 -v ns=2.35833e+07 'BEGIN { printf "%.*fms\n", p, ns / 1E6 }'
+ lat_array_ref[i]=23.58ms
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v p=2 -v ns=1.88862e+07 'BEGIN { printf "%.*fms\n", p, ns / 1E6 }'
+ lat_array_ref[i]=18.89ms
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v p=2 -v ns=2.06842e+07 'BEGIN { printf "%.*fms\n", p, ns / 1E6 }'
+ lat_array_ref[i]=20.68ms
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v p=2 -v ns=3.31229e+07 'BEGIN { printf "%.*fms\n", p, ns / 1E6 }'
+ lat_array_ref[i]=33.12ms
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v p=2 -v ns=7.61166e+07 'BEGIN { printf "%.*fms\n", p, ns / 1E6 }'
+ lat_array_ref[i]=76.12ms
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v p=2 -v ns=8.85067e+07 'BEGIN { printf "%.*fms\n", p, ns / 1E6 }'
+ lat_array_ref[i]=88.51ms
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v p=2 -v ns=1.38894e+08 'BEGIN { printf "%.*fms\n", p, ns / 1E6 }'
+ lat_array_ref[i]=138.89ms
+ (( i++ ))
+ (( i < ROW_COUNT ))
+ echo '| File Size | BlockSize | nrfiles | Bandwidth in (GB/sec) | IOPs | IOPs Avg Latency (ms) |'
+ echo '|---|---|---|---|---|---|'
+ (( i = 0 ))
+ (( i < ROW_COUNT ))
+ echo '| 128K | 128K | 30 | 0.757 | 5.77K | 18.11ms |'
+ (( i++ ))
+ (( i < ROW_COUNT ))
+ echo '| 256K | 128K | 30 | 1.440 | 10.99K | 9.40ms |'
+ (( i++ ))
+ (( i < ROW_COUNT ))
+ echo '| 1MB | 1M | 30 | 4.199 | 4.00K | 23.58ms |'
+ (( i++ ))
+ (( i < ROW_COUNT ))
+ echo '| 5MB | 1M | 20 | 6.493 | 6.19K | 18.89ms |'
+ (( i++ ))
+ (( i < ROW_COUNT ))
+ echo '| 10MB | 1M | 20 | 7.166 | 6.83K | 20.68ms |'
+ (( i++ ))
+ (( i < ROW_COUNT ))
+ echo '| 50MB | 1M | 20 | 7.453 | 7.11K | 33.12ms |'
+ (( i++ ))
+ (( i < ROW_COUNT ))
+ echo '| 100MB | 1M | 10 | 7.220 | 6.89K | 76.12ms |'
+ (( i++ ))
+ (( i < ROW_COUNT ))
+ echo '| 200MB | 1M | 10 | 6.730 | 6.42K | 88.51ms |'
+ (( i++ ))
+ (( i < ROW_COUNT ))
+ echo '| 1GB | 1M | 10 | 7.606 | 7.25K | 138.89ms |'
+ (( i++ ))
+ (( i < ROW_COUNT ))
+ echo ''
+ create_table 'Random Reads' /tmp/create_benchmark_tables.B0pnL6/gcsfuse-random-read-workload-benchmark read MB
+ local 'table_name=Random Reads'
+ local file=/tmp/create_benchmark_tables.B0pnL6/gcsfuse-random-read-workload-benchmark
+ local workflow_type=read
+ local bw_in=MB
+ echo '### Random Reads'
++ job_count /tmp/create_benchmark_tables.B0pnL6/gcsfuse-random-read-workload-benchmark_1.json
++ local file=/tmp/create_benchmark_tables.B0pnL6/gcsfuse-random-read-workload-benchmark_1.json
++ local count
+++ jq '.jobs | length' /tmp/create_benchmark_tables.B0pnL6/gcsfuse-random-read-workload-benchmark_1.json
++ count=9
++ [[ 9 -le 0 ]]
++ echo 9
+ ROW_COUNT=9
+ populate_all_columns /tmp/create_benchmark_tables.B0pnL6/gcsfuse-random-read-workload-benchmark read
+ local file=/tmp/create_benchmark_tables.B0pnL6/gcsfuse-random-read-workload-benchmark
+ local op_type=read
+ local lat_ns_op_type=read.lat_ns
+ populate_array_from_jq /tmp/create_benchmark_tables.B0pnL6/gcsfuse-random-read-workload-benchmark_1.json '.jobs[]?."job options"' '."global options"' bs bs
+ local file=/tmp/create_benchmark_tables.B0pnL6/gcsfuse-random-read-workload-benchmark_1.json
+ local 'jq_job_path_template=.jobs[]?."job options"'
+ local 'jq_global_path_template=."global options"'
+ local field_name=bs
+ local -n array_ref=bs
+ array_ref=()
+ local 'jq_job_query=.jobs[]?."job options"["bs"]?'
+ local 'jq_global_query=."global options"["bs"]?'
+ mapfile -t values
++ jq -r '.jobs[]?."job options"["bs"]?' /tmp/create_benchmark_tables.B0pnL6/gcsfuse-random-read-workload-benchmark_1.json
+ local i
+ for i in "${!values[@]}"
+ local value=128K
+ [[ 128K == \n\u\l\l ]]
+ [[ 128K == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=128K
+ [[ 128K == \n\u\l\l ]]
+ [[ 128K == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=1M
+ [[ 1M == \n\u\l\l ]]
+ [[ 1M == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=1M
+ [[ 1M == \n\u\l\l ]]
+ [[ 1M == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=1M
+ [[ 1M == \n\u\l\l ]]
+ [[ 1M == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=1M
+ [[ 1M == \n\u\l\l ]]
+ [[ 1M == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=1M
+ [[ 1M == \n\u\l\l ]]
+ [[ 1M == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=1M
+ [[ 1M == \n\u\l\l ]]
+ [[ 1M == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=1M
+ [[ 1M == \n\u\l\l ]]
+ [[ 1M == \n\u\l\l ]]
+ array_ref+=("$value")
+ [[ 9 -ne 9 ]]
+ populate_array_from_jq /tmp/create_benchmark_tables.B0pnL6/gcsfuse-random-read-workload-benchmark_1.json '.jobs[]?."job options"' '."global options"' filesize filesize
+ local file=/tmp/create_benchmark_tables.B0pnL6/gcsfuse-random-read-workload-benchmark_1.json
+ local 'jq_job_path_template=.jobs[]?."job options"'
+ local 'jq_global_path_template=."global options"'
+ local field_name=filesize
+ local -n array_ref=filesize
+ array_ref=()
+ local 'jq_job_query=.jobs[]?."job options"["filesize"]?'
+ local 'jq_global_query=."global options"["filesize"]?'
+ mapfile -t values
++ jq -r '.jobs[]?."job options"["filesize"]?' /tmp/create_benchmark_tables.B0pnL6/gcsfuse-random-read-workload-benchmark_1.json
+ local i
+ for i in "${!values[@]}"
+ local value=128K
+ [[ 128K == \n\u\l\l ]]
+ [[ 128K == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=256K
+ [[ 256K == \n\u\l\l ]]
+ [[ 256K == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=1MB
+ [[ 1MB == \n\u\l\l ]]
+ [[ 1MB == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=5MB
+ [[ 5MB == \n\u\l\l ]]
+ [[ 5MB == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=10MB
+ [[ 10MB == \n\u\l\l ]]
+ [[ 10MB == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=50MB
+ [[ 50MB == \n\u\l\l ]]
+ [[ 50MB == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=100MB
+ [[ 100MB == \n\u\l\l ]]
+ [[ 100MB == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=200MB
+ [[ 200MB == \n\u\l\l ]]
+ [[ 200MB == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=1GB
+ [[ 1GB == \n\u\l\l ]]
+ [[ 1GB == \n\u\l\l ]]
+ array_ref+=("$value")
+ [[ 9 -ne 9 ]]
+ populate_array_from_jq /tmp/create_benchmark_tables.B0pnL6/gcsfuse-random-read-workload-benchmark_1.json '.jobs[]?."job options"' '."global options"' nrfiles nrfiles
+ local file=/tmp/create_benchmark_tables.B0pnL6/gcsfuse-random-read-workload-benchmark_1.json
+ local 'jq_job_path_template=.jobs[]?."job options"'
+ local 'jq_global_path_template=."global options"'
+ local field_name=nrfiles
+ local -n array_ref=nrfiles
+ array_ref=()
+ local 'jq_job_query=.jobs[]?."job options"["nrfiles"]?'
+ local 'jq_global_query=."global options"["nrfiles"]?'
+ mapfile -t values
++ jq -r '.jobs[]?."job options"["nrfiles"]?' /tmp/create_benchmark_tables.B0pnL6/gcsfuse-random-read-workload-benchmark_1.json
+ local i
+ for i in "${!values[@]}"
+ local value=30
+ [[ 30 == \n\u\l\l ]]
+ [[ 30 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=30
+ [[ 30 == \n\u\l\l ]]
+ [[ 30 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=30
+ [[ 30 == \n\u\l\l ]]
+ [[ 30 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=20
+ [[ 20 == \n\u\l\l ]]
+ [[ 20 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=20
+ [[ 20 == \n\u\l\l ]]
+ [[ 20 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=20
+ [[ 20 == \n\u\l\l ]]
+ [[ 20 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=10
+ [[ 10 == \n\u\l\l ]]
+ [[ 10 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=10
+ [[ 10 == \n\u\l\l ]]
+ [[ 10 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=10
+ [[ 10 == \n\u\l\l ]]
+ [[ 10 == \n\u\l\l ]]
+ array_ref+=("$value")
+ [[ 9 -ne 9 ]]
+ populate_avg_in_array_for_all_runs /tmp/create_benchmark_tables.B0pnL6/gcsfuse-random-read-workload-benchmark '.jobs[]?.read' '."global options"' bw_bytes bw_bytes
+ local file=/tmp/create_benchmark_tables.B0pnL6/gcsfuse-random-read-workload-benchmark
+ local 'jq_job_path_template=.jobs[]?.read'
+ local 'jq_global_path_template=."global options"'
+ local field_name=bw_bytes
+ local -n array_ref=bw_bytes
+ sum=()
+ local sum
++ seq 1 1
+ for i in $(seq 1 "$BENCHMARK_COUNT")
+ curr_arr=()
+ local curr_arr
+ local curr_file_name=/tmp/create_benchmark_tables.B0pnL6/gcsfuse-random-read-workload-benchmark_1.json
+ populate_array_from_jq /tmp/create_benchmark_tables.B0pnL6/gcsfuse-random-read-workload-benchmark_1.json '.jobs[]?.read' '."global options"' bw_bytes curr_arr
+ local file=/tmp/create_benchmark_tables.B0pnL6/gcsfuse-random-read-workload-benchmark_1.json
+ local 'jq_job_path_template=.jobs[]?.read'
+ local 'jq_global_path_template=."global options"'
+ local field_name=bw_bytes
+ local -n array_ref=curr_arr
+ array_ref=()
+ local 'jq_job_query=.jobs[]?.read["bw_bytes"]?'
+ local 'jq_global_query=."global options"["bw_bytes"]?'
+ mapfile -t values
++ jq -r '.jobs[]?.read["bw_bytes"]?' /tmp/create_benchmark_tables.B0pnL6/gcsfuse-random-read-workload-benchmark_1.json
+ local i
+ for i in "${!values[@]}"
+ local value=758006746
+ [[ 758006746 == \n\u\l\l ]]
+ [[ 758006746 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=893196947
+ [[ 893196947 == \n\u\l\l ]]
+ [[ 893196947 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=4087849583
+ [[ 4087849583 == \n\u\l\l ]]
+ [[ 4087849583 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=3630449770
+ [[ 3630449770 == \n\u\l\l ]]
+ [[ 3630449770 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=4032984615
+ [[ 4032984615 == \n\u\l\l ]]
+ [[ 4032984615 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=3684263738
+ [[ 3684263738 == \n\u\l\l ]]
+ [[ 3684263738 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=3595920375
+ [[ 3595920375 == \n\u\l\l ]]
+ [[ 3595920375 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=3353850121
+ [[ 3353850121 == \n\u\l\l ]]
+ [[ 3353850121 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=1494390593
+ [[ 1494390593 == \n\u\l\l ]]
+ [[ 1494390593 == \n\u\l\l ]]
+ array_ref+=("$value")
+ [[ 9 -ne 9 ]]
+ [[ 1 -eq 1 ]]
+ sum=("${curr_arr[@]}")
+ (( i = 0 ))
+ (( i < ROW_COUNT ))
++ awk -v s=758006746 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=758006746
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=893196947 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=893196947
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=4087849583 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=4087849583
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=3630449770 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=3630449770
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=4032984615 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=4032984615
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=3684263738 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=3684263738
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=3595920375 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=3595920375
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=3353850121 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=3353850121
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=1494390593 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=1494390593
+ (( i++ ))
+ (( i < ROW_COUNT ))
+ populate_avg_in_array_for_all_runs /tmp/create_benchmark_tables.B0pnL6/gcsfuse-random-read-workload-benchmark '.jobs[]?.read' '."global options"' iops iops
+ local file=/tmp/create_benchmark_tables.B0pnL6/gcsfuse-random-read-workload-benchmark
+ local 'jq_job_path_template=.jobs[]?.read'
+ local 'jq_global_path_template=."global options"'
+ local field_name=iops
+ local -n array_ref=iops
+ sum=()
+ local sum
++ seq 1 1
+ for i in $(seq 1 "$BENCHMARK_COUNT")
+ curr_arr=()
+ local curr_arr
+ local curr_file_name=/tmp/create_benchmark_tables.B0pnL6/gcsfuse-random-read-workload-benchmark_1.json
+ populate_array_from_jq /tmp/create_benchmark_tables.B0pnL6/gcsfuse-random-read-workload-benchmark_1.json '.jobs[]?.read' '."global options"' iops curr_arr
+ local file=/tmp/create_benchmark_tables.B0pnL6/gcsfuse-random-read-workload-benchmark_1.json
+ local 'jq_job_path_template=.jobs[]?.read'
+ local 'jq_global_path_template=."global options"'
+ local field_name=iops
+ local -n array_ref=curr_arr
+ array_ref=()
+ local 'jq_job_query=.jobs[]?.read["iops"]?'
+ local 'jq_global_query=."global options"["iops"]?'
+ mapfile -t values
++ jq -r '.jobs[]?.read["iops"]?' /tmp/create_benchmark_tables.B0pnL6/gcsfuse-random-read-workload-benchmark_1.json
+ local i
+ for i in "${!values[@]}"
+ local value=5783.132530
+ [[ 5783.132530 == \n\u\l\l ]]
+ [[ 5783.132530 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=6814.551908
+ [[ 6814.551908 == \n\u\l\l ]]
+ [[ 6814.551908 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=3898.477157
+ [[ 3898.477157 == \n\u\l\l ]]
+ [[ 3898.477157 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=3462.266703
+ [[ 3462.266703 == \n\u\l\l ]]
+ [[ 3462.266703 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=3846.153846
+ [[ 3846.153846 == \n\u\l\l ]]
+ [[ 3846.153846 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=3513.587702
+ [[ 3513.587702 == \n\u\l\l ]]
+ [[ 3513.587702 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=3429.336906
+ [[ 3429.336906 == \n\u\l\l ]]
+ [[ 3429.336906 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=3198.480722
+ [[ 3198.480722 == \n\u\l\l ]]
+ [[ 3198.480722 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=1425.161928
+ [[ 1425.161928 == \n\u\l\l ]]
+ [[ 1425.161928 == \n\u\l\l ]]
+ array_ref+=("$value")
+ [[ 9 -ne 9 ]]
+ [[ 1 -eq 1 ]]
+ sum=("${curr_arr[@]}")
+ (( i = 0 ))
+ (( i < ROW_COUNT ))
++ awk -v s=5783.132530 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=5783.13
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=6814.551908 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=6814.55
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=3898.477157 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=3898.48
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=3462.266703 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=3462.27
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=3846.153846 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=3846.15
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=3513.587702 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=3513.59
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=3429.336906 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=3429.34
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=3198.480722 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=3198.48
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=1425.161928 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=1425.16
+ (( i++ ))
+ (( i < ROW_COUNT ))
+ populate_avg_in_array_for_all_runs /tmp/create_benchmark_tables.B0pnL6/gcsfuse-random-read-workload-benchmark '.jobs[]?.read.lat_ns' '."global options"' mean lat_mean
+ local file=/tmp/create_benchmark_tables.B0pnL6/gcsfuse-random-read-workload-benchmark
+ local 'jq_job_path_template=.jobs[]?.read.lat_ns'
+ local 'jq_global_path_template=."global options"'
+ local field_name=mean
+ local -n array_ref=lat_mean
+ sum=()
+ local sum
++ seq 1 1
+ for i in $(seq 1 "$BENCHMARK_COUNT")
+ curr_arr=()
+ local curr_arr
+ local curr_file_name=/tmp/create_benchmark_tables.B0pnL6/gcsfuse-random-read-workload-benchmark_1.json
+ populate_array_from_jq /tmp/create_benchmark_tables.B0pnL6/gcsfuse-random-read-workload-benchmark_1.json '.jobs[]?.read.lat_ns' '."global options"' mean curr_arr
+ local file=/tmp/create_benchmark_tables.B0pnL6/gcsfuse-random-read-workload-benchmark_1.json
+ local 'jq_job_path_template=.jobs[]?.read.lat_ns'
+ local 'jq_global_path_template=."global options"'
+ local field_name=mean
+ local -n array_ref=curr_arr
+ array_ref=()
+ local 'jq_job_query=.jobs[]?.read.lat_ns["mean"]?'
+ local 'jq_global_query=."global options"["mean"]?'
+ mapfile -t values
++ jq -r '.jobs[]?.read.lat_ns["mean"]?' /tmp/create_benchmark_tables.B0pnL6/gcsfuse-random-read-workload-benchmark_1.json
+ local i
+ for i in "${!values[@]}"
+ local value=17610687.897656
+ [[ 17610687.897656 == \n\u\l\l ]]
+ [[ 17610687.897656 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=14875814.398568
+ [[ 14875814.398568 == \n\u\l\l ]]
+ [[ 14875814.398568 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=23122448.701042
+ [[ 23122448.701042 == \n\u\l\l ]]
+ [[ 23122448.701042 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=33948541.588828
+ [[ 33948541.588828 == \n\u\l\l ]]
+ [[ 33948541.588828 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=41643082.547734
+ [[ 41643082.547734 == \n\u\l\l ]]
+ [[ 41643082.547734 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=83515674.890406
+ [[ 83515674.890406 == \n\u\l\l ]]
+ [[ 83515674.890406 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=205668062.443383
+ [[ 205668062.443383 == \n\u\l\l ]]
+ [[ 205668062.443383 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=283694913.915668
+ [[ 283694913.915668 == \n\u\l\l ]]
+ [[ 283694913.915668 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=585075906.866069
+ [[ 585075906.866069 == \n\u\l\l ]]
+ [[ 585075906.866069 == \n\u\l\l ]]
+ array_ref+=("$value")
+ [[ 9 -ne 9 ]]
+ [[ 1 -eq 1 ]]
+ sum=("${curr_arr[@]}")
+ (( i = 0 ))
+ (( i < ROW_COUNT ))
++ awk -v s=17610687.897656 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=1.76107e+07
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=14875814.398568 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=1.48758e+07
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=23122448.701042 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=2.31224e+07
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=33948541.588828 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=3.39485e+07
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=41643082.547734 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=4.16431e+07
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=83515674.890406 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=8.35157e+07
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=205668062.443383 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=2.05668e+08
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=283694913.915668 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=2.83695e+08
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=585075906.866069 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=5.85076e+08
+ (( i++ ))
+ (( i < ROW_COUNT ))
+ convert_bytes_to MB
+ local division=1000000
+ local precision=3
+ (( i = 0 ))
+ (( i < ROW_COUNT ))
++ awk -v prec=3 -v div=1000000 -v bval=758006746 'BEGIN { printf "%.*f\n", prec, bval / div }'
+ bw_bytes[i]=758.007
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v prec=3 -v div=1000000 -v bval=893196947 'BEGIN { printf "%.*f\n", prec, bval / div }'
+ bw_bytes[i]=893.197
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v prec=3 -v div=1000000 -v bval=4087849583 'BEGIN { printf "%.*f\n", prec, bval / div }'
+ bw_bytes[i]=4087.850
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v prec=3 -v div=1000000 -v bval=3630449770 'BEGIN { printf "%.*f\n", prec, bval / div }'
+ bw_bytes[i]=3630.450
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v prec=3 -v div=1000000 -v bval=4032984615 'BEGIN { printf "%.*f\n", prec, bval / div }'
+ bw_bytes[i]=4032.985
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v prec=3 -v div=1000000 -v bval=3684263738 'BEGIN { printf "%.*f\n", prec, bval / div }'
+ bw_bytes[i]=3684.264
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v prec=3 -v div=1000000 -v bval=3595920375 'BEGIN { printf "%.*f\n", prec, bval / div }'
+ bw_bytes[i]=3595.920
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v prec=3 -v div=1000000 -v bval=3353850121 'BEGIN { printf "%.*f\n", prec, bval / div }'
+ bw_bytes[i]=3353.850
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v prec=3 -v div=1000000 -v bval=1494390593 'BEGIN { printf "%.*f\n", prec, bval / div }'
+ bw_bytes[i]=1494.391
+ (( i++ ))
+ (( i < ROW_COUNT ))
+ format_iops_to_kilo
+ (( i = 0 ))
+ (( i < ROW_COUNT ))
++ awk -v n=5783.13 'BEGIN { printf "%.2fK\n", n / 1000 }'
+ iops[i]=5.78K
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v n=6814.55 'BEGIN { printf "%.2fK\n", n / 1000 }'
+ iops[i]=6.81K
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v n=3898.48 'BEGIN { printf "%.2fK\n", n / 1000 }'
+ iops[i]=3.90K
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v n=3462.27 'BEGIN { printf "%.2fK\n", n / 1000 }'
+ iops[i]=3.46K
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v n=3846.15 'BEGIN { printf "%.2fK\n", n / 1000 }'
+ iops[i]=3.85K
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v n=3513.59 'BEGIN { printf "%.2fK\n", n / 1000 }'
+ iops[i]=3.51K
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v n=3429.34 'BEGIN { printf "%.2fK\n", n / 1000 }'
+ iops[i]=3.43K
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v n=3198.48 'BEGIN { printf "%.2fK\n", n / 1000 }'
+ iops[i]=3.20K
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v n=1425.16 'BEGIN { printf "%.2fK\n", n / 1000 }'
+ iops[i]=1.43K
+ (( i++ ))
+ (( i < ROW_COUNT ))
+ convert_lat_mean_ns_to_ms lat_mean
+ local -n lat_array_ref=lat_mean
+ local precision=2
+ (( i = 0 ))
+ (( i < ROW_COUNT ))
++ awk -v p=2 -v ns=1.76107e+07 'BEGIN { printf "%.*fms\n", p, ns / 1E6 }'
+ lat_array_ref[i]=17.61ms
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v p=2 -v ns=1.48758e+07 'BEGIN { printf "%.*fms\n", p, ns / 1E6 }'
+ lat_array_ref[i]=14.88ms
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v p=2 -v ns=2.31224e+07 'BEGIN { printf "%.*fms\n", p, ns / 1E6 }'
+ lat_array_ref[i]=23.12ms
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v p=2 -v ns=3.39485e+07 'BEGIN { printf "%.*fms\n", p, ns / 1E6 }'
+ lat_array_ref[i]=33.95ms
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v p=2 -v ns=4.16431e+07 'BEGIN { printf "%.*fms\n", p, ns / 1E6 }'
+ lat_array_ref[i]=41.64ms
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v p=2 -v ns=8.35157e+07 'BEGIN { printf "%.*fms\n", p, ns / 1E6 }'
+ lat_array_ref[i]=83.52ms
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v p=2 -v ns=2.05668e+08 'BEGIN { printf "%.*fms\n", p, ns / 1E6 }'
+ lat_array_ref[i]=205.67ms
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v p=2 -v ns=2.83695e+08 'BEGIN { printf "%.*fms\n", p, ns / 1E6 }'
+ lat_array_ref[i]=283.69ms
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v p=2 -v ns=5.85076e+08 'BEGIN { printf "%.*fms\n", p, ns / 1E6 }'
+ lat_array_ref[i]=585.08ms
+ (( i++ ))
+ (( i < ROW_COUNT ))
+ echo '| File Size | BlockSize | nrfiles | Bandwidth in (MB/sec) | IOPs | IOPs Avg Latency (ms) |'
+ echo '|---|---|---|---|---|---|'
+ (( i = 0 ))
+ (( i < ROW_COUNT ))
+ echo '| 128K | 128K | 30 | 758.007 | 5.78K | 17.61ms |'
+ (( i++ ))
+ (( i < ROW_COUNT ))
+ echo '| 256K | 128K | 30 | 893.197 | 6.81K | 14.88ms |'
+ (( i++ ))
+ (( i < ROW_COUNT ))
+ echo '| 1MB | 1M | 30 | 4087.850 | 3.90K | 23.12ms |'
+ (( i++ ))
+ (( i < ROW_COUNT ))
+ echo '| 5MB | 1M | 20 | 3630.450 | 3.46K | 33.95ms |'
+ (( i++ ))
+ (( i < ROW_COUNT ))
+ echo '| 10MB | 1M | 20 | 4032.985 | 3.85K | 41.64ms |'
+ (( i++ ))
+ (( i < ROW_COUNT ))
+ echo '| 50MB | 1M | 20 | 3684.264 | 3.51K | 83.52ms |'
+ (( i++ ))
+ (( i < ROW_COUNT ))
+ echo '| 100MB | 1M | 10 | 3595.920 | 3.43K | 205.67ms |'
+ (( i++ ))
+ (( i < ROW_COUNT ))
+ echo '| 200MB | 1M | 10 | 3353.850 | 3.20K | 283.69ms |'
+ (( i++ ))
+ (( i < ROW_COUNT ))
+ echo '| 1GB | 1M | 10 | 1494.391 | 1.43K | 585.08ms |'
+ (( i++ ))
+ (( i < ROW_COUNT ))
+ echo ''
+ create_table 'Sequential Writes' /tmp/create_benchmark_tables.B0pnL6/gcsfuse-write-workload-benchmark write MB
+ local 'table_name=Sequential Writes'
+ local file=/tmp/create_benchmark_tables.B0pnL6/gcsfuse-write-workload-benchmark
+ local workflow_type=write
+ local bw_in=MB
+ echo '### Sequential Writes'
++ job_count /tmp/create_benchmark_tables.B0pnL6/gcsfuse-write-workload-benchmark_1.json
++ local file=/tmp/create_benchmark_tables.B0pnL6/gcsfuse-write-workload-benchmark_1.json
++ local count
+++ jq '.jobs | length' /tmp/create_benchmark_tables.B0pnL6/gcsfuse-write-workload-benchmark_1.json
++ count=5
++ [[ 5 -le 0 ]]
++ echo 5
+ ROW_COUNT=5
+ populate_all_columns /tmp/create_benchmark_tables.B0pnL6/gcsfuse-write-workload-benchmark write
+ local file=/tmp/create_benchmark_tables.B0pnL6/gcsfuse-write-workload-benchmark
+ local op_type=write
+ local lat_ns_op_type=write.lat_ns
+ populate_array_from_jq /tmp/create_benchmark_tables.B0pnL6/gcsfuse-write-workload-benchmark_1.json '.jobs[]?."job options"' '."global options"' bs bs
+ local file=/tmp/create_benchmark_tables.B0pnL6/gcsfuse-write-workload-benchmark_1.json
+ local 'jq_job_path_template=.jobs[]?."job options"'
+ local 'jq_global_path_template=."global options"'
+ local field_name=bs
+ local -n array_ref=bs
+ array_ref=()
+ local 'jq_job_query=.jobs[]?."job options"["bs"]?'
+ local 'jq_global_query=."global options"["bs"]?'
+ mapfile -t values
++ jq -r '.jobs[]?."job options"["bs"]?' /tmp/create_benchmark_tables.B0pnL6/gcsfuse-write-workload-benchmark_1.json
+ local i
+ for i in "${!values[@]}"
+ local value=16K
+ [[ 16K == \n\u\l\l ]]
+ [[ 16K == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=null
+ [[ null == \n\u\l\l ]]
++ jq -r '."global options"["bs"]?' /tmp/create_benchmark_tables.B0pnL6/gcsfuse-write-workload-benchmark_1.json
+ value=1M
+ [[ 1M == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=null
+ [[ null == \n\u\l\l ]]
++ jq -r '."global options"["bs"]?' /tmp/create_benchmark_tables.B0pnL6/gcsfuse-write-workload-benchmark_1.json
+ value=1M
+ [[ 1M == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=null
+ [[ null == \n\u\l\l ]]
++ jq -r '."global options"["bs"]?' /tmp/create_benchmark_tables.B0pnL6/gcsfuse-write-workload-benchmark_1.json
+ value=1M
+ [[ 1M == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=null
+ [[ null == \n\u\l\l ]]
++ jq -r '."global options"["bs"]?' /tmp/create_benchmark_tables.B0pnL6/gcsfuse-write-workload-benchmark_1.json
+ value=1M
+ [[ 1M == \n\u\l\l ]]
+ array_ref+=("$value")
+ [[ 5 -ne 5 ]]
+ populate_array_from_jq /tmp/create_benchmark_tables.B0pnL6/gcsfuse-write-workload-benchmark_1.json '.jobs[]?."job options"' '."global options"' filesize filesize
+ local file=/tmp/create_benchmark_tables.B0pnL6/gcsfuse-write-workload-benchmark_1.json
+ local 'jq_job_path_template=.jobs[]?."job options"'
+ local 'jq_global_path_template=."global options"'
+ local field_name=filesize
+ local -n array_ref=filesize
+ array_ref=()
+ local 'jq_job_query=.jobs[]?."job options"["filesize"]?'
+ local 'jq_global_query=."global options"["filesize"]?'
+ mapfile -t values
++ jq -r '.jobs[]?."job options"["filesize"]?' /tmp/create_benchmark_tables.B0pnL6/gcsfuse-write-workload-benchmark_1.json
+ local i
+ for i in "${!values[@]}"
+ local value=256K
+ [[ 256K == \n\u\l\l ]]
+ [[ 256K == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=1M
+ [[ 1M == \n\u\l\l ]]
+ [[ 1M == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=50M
+ [[ 50M == \n\u\l\l ]]
+ [[ 50M == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=100M
+ [[ 100M == \n\u\l\l ]]
+ [[ 100M == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=1G
+ [[ 1G == \n\u\l\l ]]
+ [[ 1G == \n\u\l\l ]]
+ array_ref+=("$value")
+ [[ 5 -ne 5 ]]
+ populate_array_from_jq /tmp/create_benchmark_tables.B0pnL6/gcsfuse-write-workload-benchmark_1.json '.jobs[]?."job options"' '."global options"' nrfiles nrfiles
+ local file=/tmp/create_benchmark_tables.B0pnL6/gcsfuse-write-workload-benchmark_1.json
+ local 'jq_job_path_template=.jobs[]?."job options"'
+ local 'jq_global_path_template=."global options"'
+ local field_name=nrfiles
+ local -n array_ref=nrfiles
+ array_ref=()
+ local 'jq_job_query=.jobs[]?."job options"["nrfiles"]?'
+ local 'jq_global_query=."global options"["nrfiles"]?'
+ mapfile -t values
++ jq -r '.jobs[]?."job options"["nrfiles"]?' /tmp/create_benchmark_tables.B0pnL6/gcsfuse-write-workload-benchmark_1.json
+ local i
+ for i in "${!values[@]}"
+ local value=30
+ [[ 30 == \n\u\l\l ]]
+ [[ 30 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=30
+ [[ 30 == \n\u\l\l ]]
+ [[ 30 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=20
+ [[ 20 == \n\u\l\l ]]
+ [[ 20 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=10
+ [[ 10 == \n\u\l\l ]]
+ [[ 10 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=2
+ [[ 2 == \n\u\l\l ]]
+ [[ 2 == \n\u\l\l ]]
+ array_ref+=("$value")
+ [[ 5 -ne 5 ]]
+ populate_avg_in_array_for_all_runs /tmp/create_benchmark_tables.B0pnL6/gcsfuse-write-workload-benchmark '.jobs[]?.write' '."global options"' bw_bytes bw_bytes
+ local file=/tmp/create_benchmark_tables.B0pnL6/gcsfuse-write-workload-benchmark
+ local 'jq_job_path_template=.jobs[]?.write'
+ local 'jq_global_path_template=."global options"'
+ local field_name=bw_bytes
+ local -n array_ref=bw_bytes
+ sum=()
+ local sum
++ seq 1 1
+ for i in $(seq 1 "$BENCHMARK_COUNT")
+ curr_arr=()
+ local curr_arr
+ local curr_file_name=/tmp/create_benchmark_tables.B0pnL6/gcsfuse-write-workload-benchmark_1.json
+ populate_array_from_jq /tmp/create_benchmark_tables.B0pnL6/gcsfuse-write-workload-benchmark_1.json '.jobs[]?.write' '."global options"' bw_bytes curr_arr
+ local file=/tmp/create_benchmark_tables.B0pnL6/gcsfuse-write-workload-benchmark_1.json
+ local 'jq_job_path_template=.jobs[]?.write'
+ local 'jq_global_path_template=."global options"'
+ local field_name=bw_bytes
+ local -n array_ref=curr_arr
+ array_ref=()
+ local 'jq_job_query=.jobs[]?.write["bw_bytes"]?'
+ local 'jq_global_query=."global options"["bw_bytes"]?'
+ mapfile -t values
++ jq -r '.jobs[]?.write["bw_bytes"]?' /tmp/create_benchmark_tables.B0pnL6/gcsfuse-write-workload-benchmark_1.json
+ local i
+ for i in "${!values[@]}"
+ local value=253907131
+ [[ 253907131 == \n\u\l\l ]]
+ [[ 253907131 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=908513501
+ [[ 908513501 == \n\u\l\l ]]
+ [[ 908513501 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=3095345720
+ [[ 3095345720 == \n\u\l\l ]]
+ [[ 3095345720 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=2719096848
+ [[ 2719096848 == \n\u\l\l ]]
+ [[ 2719096848 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=175053944
+ [[ 175053944 == \n\u\l\l ]]
+ [[ 175053944 == \n\u\l\l ]]
+ array_ref+=("$value")
+ [[ 5 -ne 5 ]]
+ [[ 1 -eq 1 ]]
+ sum=("${curr_arr[@]}")
+ (( i = 0 ))
+ (( i < ROW_COUNT ))
++ awk -v s=253907131 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=253907131
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=908513501 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=908513501
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=3095345720 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=3095345720
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=2719096848 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=2719096848
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=175053944 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=175053944
+ (( i++ ))
+ (( i < ROW_COUNT ))
+ populate_avg_in_array_for_all_runs /tmp/create_benchmark_tables.B0pnL6/gcsfuse-write-workload-benchmark '.jobs[]?.write' '."global options"' iops iops
+ local file=/tmp/create_benchmark_tables.B0pnL6/gcsfuse-write-workload-benchmark
+ local 'jq_job_path_template=.jobs[]?.write'
+ local 'jq_global_path_template=."global options"'
+ local field_name=iops
+ local -n array_ref=iops
+ sum=()
+ local sum
++ seq 1 1
+ for i in $(seq 1 "$BENCHMARK_COUNT")
+ curr_arr=()
+ local curr_arr
+ local curr_file_name=/tmp/create_benchmark_tables.B0pnL6/gcsfuse-write-workload-benchmark_1.json
+ populate_array_from_jq /tmp/create_benchmark_tables.B0pnL6/gcsfuse-write-workload-benchmark_1.json '.jobs[]?.write' '."global options"' iops curr_arr
+ local file=/tmp/create_benchmark_tables.B0pnL6/gcsfuse-write-workload-benchmark_1.json
+ local 'jq_job_path_template=.jobs[]?.write'
+ local 'jq_global_path_template=."global options"'
+ local field_name=iops
+ local -n array_ref=curr_arr
+ array_ref=()
+ local 'jq_job_query=.jobs[]?.write["iops"]?'
+ local 'jq_global_query=."global options"["iops"]?'
+ mapfile -t values
++ jq -r '.jobs[]?.write["iops"]?' /tmp/create_benchmark_tables.B0pnL6/gcsfuse-write-workload-benchmark_1.json
+ local i
+ for i in "${!values[@]}"
+ local value=15497.261459
+ [[ 15497.261459 == \n\u\l\l ]]
+ [[ 15497.261459 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=866.425993
+ [[ 866.425993 == \n\u\l\l ]]
+ [[ 866.425993 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=2951.951715
+ [[ 2951.951715 == \n\u\l\l ]]
+ [[ 2951.951715 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=2593.132829
+ [[ 2593.132829 == \n\u\l\l ]]
+ [[ 2593.132829 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=166.944451
+ [[ 166.944451 == \n\u\l\l ]]
+ [[ 166.944451 == \n\u\l\l ]]
+ array_ref+=("$value")
+ [[ 5 -ne 5 ]]
+ [[ 1 -eq 1 ]]
+ sum=("${curr_arr[@]}")
+ (( i = 0 ))
+ (( i < ROW_COUNT ))
++ awk -v s=15497.261459 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=15497.3
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=866.425993 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=866.426
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=2951.951715 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=2951.95
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=2593.132829 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=2593.13
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=166.944451 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=166.944
+ (( i++ ))
+ (( i < ROW_COUNT ))
+ populate_avg_in_array_for_all_runs /tmp/create_benchmark_tables.B0pnL6/gcsfuse-write-workload-benchmark '.jobs[]?.write.lat_ns' '."global options"' mean lat_mean
+ local file=/tmp/create_benchmark_tables.B0pnL6/gcsfuse-write-workload-benchmark
+ local 'jq_job_path_template=.jobs[]?.write.lat_ns'
+ local 'jq_global_path_template=."global options"'
+ local field_name=mean
+ local -n array_ref=lat_mean
+ sum=()
+ local sum
++ seq 1 1
+ for i in $(seq 1 "$BENCHMARK_COUNT")
+ curr_arr=()
+ local curr_arr
+ local curr_file_name=/tmp/create_benchmark_tables.B0pnL6/gcsfuse-write-workload-benchmark_1.json
+ populate_array_from_jq /tmp/create_benchmark_tables.B0pnL6/gcsfuse-write-workload-benchmark_1.json '.jobs[]?.write.lat_ns' '."global options"' mean curr_arr
+ local file=/tmp/create_benchmark_tables.B0pnL6/gcsfuse-write-workload-benchmark_1.json
+ local 'jq_job_path_template=.jobs[]?.write.lat_ns'
+ local 'jq_global_path_template=."global options"'
+ local field_name=mean
+ local -n array_ref=curr_arr
+ array_ref=()
+ local 'jq_job_query=.jobs[]?.write.lat_ns["mean"]?'
+ local 'jq_global_query=."global options"["mean"]?'
+ mapfile -t values
++ jq -r '.jobs[]?.write.lat_ns["mean"]?' /tmp/create_benchmark_tables.B0pnL6/gcsfuse-write-workload-benchmark_1.json
+ local i
+ for i in "${!values[@]}"
+ local value=3116329.945424
+ [[ 3116329.945424 == \n\u\l\l ]]
+ [[ 3116329.945424 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=55941148.030655
+ [[ 55941148.030655 == \n\u\l\l ]]
+ [[ 55941148.030655 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=18685279.232125
+ [[ 18685279.232125 == \n\u\l\l ]]
+ [[ 18685279.232125 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=23609525.439330
+ [[ 23609525.439330 == \n\u\l\l ]]
+ [[ 23609525.439330 == \n\u\l\l ]]
+ array_ref+=("$value")
+ for i in "${!values[@]}"
+ local value=654342048.177486
+ [[ 654342048.177486 == \n\u\l\l ]]
+ [[ 654342048.177486 == \n\u\l\l ]]
+ array_ref+=("$value")
+ [[ 5 -ne 5 ]]
+ [[ 1 -eq 1 ]]
+ sum=("${curr_arr[@]}")
+ (( i = 0 ))
+ (( i < ROW_COUNT ))
++ awk -v s=3116329.945424 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=3.11633e+06
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=55941148.030655 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=5.59411e+07
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=18685279.232125 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=1.86853e+07
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=23609525.439330 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=2.36095e+07
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v s=654342048.177486 -v c=1 'BEGIN { print s / c }'
+ array_ref[i]=6.54342e+08
+ (( i++ ))
+ (( i < ROW_COUNT ))
+ convert_bytes_to MB
+ local division=1000000
+ local precision=3
+ (( i = 0 ))
+ (( i < ROW_COUNT ))
++ awk -v prec=3 -v div=1000000 -v bval=253907131 'BEGIN { printf "%.*f\n", prec, bval / div }'
+ bw_bytes[i]=253.907
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v prec=3 -v div=1000000 -v bval=908513501 'BEGIN { printf "%.*f\n", prec, bval / div }'
+ bw_bytes[i]=908.514
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v prec=3 -v div=1000000 -v bval=3095345720 'BEGIN { printf "%.*f\n", prec, bval / div }'
+ bw_bytes[i]=3095.346
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v prec=3 -v div=1000000 -v bval=2719096848 'BEGIN { printf "%.*f\n", prec, bval / div }'
+ bw_bytes[i]=2719.097
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v prec=3 -v div=1000000 -v bval=175053944 'BEGIN { printf "%.*f\n", prec, bval / div }'
+ bw_bytes[i]=175.054
+ (( i++ ))
+ (( i < ROW_COUNT ))
+ format_iops_to_kilo
+ (( i = 0 ))
+ (( i < ROW_COUNT ))
++ awk -v n=15497.3 'BEGIN { printf "%.2fK\n", n / 1000 }'
+ iops[i]=15.50K
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v n=866.426 'BEGIN { printf "%.2fK\n", n / 1000 }'
+ iops[i]=0.87K
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v n=2951.95 'BEGIN { printf "%.2fK\n", n / 1000 }'
+ iops[i]=2.95K
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v n=2593.13 'BEGIN { printf "%.2fK\n", n / 1000 }'
+ iops[i]=2.59K
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v n=166.944 'BEGIN { printf "%.2fK\n", n / 1000 }'
+ iops[i]=0.17K
+ (( i++ ))
+ (( i < ROW_COUNT ))
+ convert_lat_mean_ns_to_ms lat_mean
+ local -n lat_array_ref=lat_mean
+ local precision=2
+ (( i = 0 ))
+ (( i < ROW_COUNT ))
++ awk -v p=2 -v ns=3.11633e+06 'BEGIN { printf "%.*fms\n", p, ns / 1E6 }'
+ lat_array_ref[i]=3.12ms
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v p=2 -v ns=5.59411e+07 'BEGIN { printf "%.*fms\n", p, ns / 1E6 }'
+ lat_array_ref[i]=55.94ms
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v p=2 -v ns=1.86853e+07 'BEGIN { printf "%.*fms\n", p, ns / 1E6 }'
+ lat_array_ref[i]=18.69ms
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v p=2 -v ns=2.36095e+07 'BEGIN { printf "%.*fms\n", p, ns / 1E6 }'
+ lat_array_ref[i]=23.61ms
+ (( i++ ))
+ (( i < ROW_COUNT ))
++ awk -v p=2 -v ns=6.54342e+08 'BEGIN { printf "%.*fms\n", p, ns / 1E6 }'
+ lat_array_ref[i]=654.34ms
+ (( i++ ))
+ (( i < ROW_COUNT ))
+ echo '| File Size | BlockSize | nrfiles | Bandwidth in (MB/sec) | IOPs | IOPs Avg Latency (ms) |'
+ echo '|---|---|---|---|---|---|'
+ (( i = 0 ))
+ (( i < ROW_COUNT ))
+ echo '| 256K | 16K | 30 | 253.907 | 15.50K | 3.12ms |'
+ (( i++ ))
+ (( i < ROW_COUNT ))
+ echo '| 1M | 1M | 30 | 908.514 | 0.87K | 55.94ms |'
+ (( i++ ))
+ (( i < ROW_COUNT ))
+ echo '| 50M | 1M | 20 | 3095.346 | 2.95K | 18.69ms |'
+ (( i++ ))
+ (( i < ROW_COUNT ))
+ echo '| 100M | 1M | 10 | 2719.097 | 2.59K | 23.61ms |'
+ (( i++ ))
+ (( i < ROW_COUNT ))
+ echo '| 1G | 1M | 2 | 175.054 | 0.17K | 654.34ms |'
+ (( i++ ))
+ (( i < ROW_COUNT ))
+ echo ''
+ gcloud storage cp /tmp/create_benchmark_tables.B0pnL6/tables.md gs://gcsfuse-release-benchmarks-results/enable_read_manager_flag/n2-standard-96/
Copying file:///tmp/create_benchmark_tables.B0pnL6/tables.md to gs://gcsfuse-release-benchmarks-results/enable_read_manager_flag/n2-standard-96/tables.md
  
..
+ echo 'Benchmark table successfully created and uploaded to gs://gcsfuse-release-benchmarks-results/enable_read_manager_flag/n2-standard-96/tables.md'
Benchmark table successfully created and uploaded to gs://gcsfuse-release-benchmarks-results/enable_read_manager_flag/n2-standard-96/tables.md
+ rm -rf /tmp/create_benchmark_tables.B0pnL6
+ gcloud storage cp gs://gcsfuse-release-benchmarks-results/enable_read_manager_flag/c4-standard-96/tables.md /tmp/update_benchmarks.YILFOC/c4-standard-96/tables.md
Copying gs://gcsfuse-release-benchmarks-results/enable_read_manager_flag/c4-standard-96/tables.md to file:///tmp/update_benchmarks.YILFOC/c4-standard-96/tables.md
  
.
+ gcloud storage cp gs://gcsfuse-release-benchmarks-results/enable_read_manager_flag/n2-standard-96/tables.md /tmp/update_benchmarks.YILFOC/n2-standard-96/tables.md
Copying gs://gcsfuse-release-benchmarks-results/enable_read_manager_flag/n2-standard-96/tables.md to file:///tmp/update_benchmarks.YILFOC/n2-standard-96/tables.md
  
.
+ cat /tmp/update_benchmarks.YILFOC/c4-standard-96/tables.md
+ echo ' '
+ cat /tmp/update_benchmarks.YILFOC/n2-standard-96/tables.md
+ CLONE_DIR=/tmp/update_benchmarks.YILFOC/gcsfuse
+ REPO_URL=https://github.com/GoogleCloudPlatform/gcsfuse.git
+ clone_gcsfuse_repo
+ echo 'Cloning gcsfuse repository from https://github.com/GoogleCloudPlatform/gcsfuse.git into /tmp/update_benchmarks.YILFOC/gcsfuse...'
Cloning gcsfuse repository from https://github.com/GoogleCloudPlatform/gcsfuse.git into /tmp/update_benchmarks.YILFOC/gcsfuse...
+ '[' -d /tmp/update_benchmarks.YILFOC/gcsfuse ']'
+ git clone https://github.com/GoogleCloudPlatform/gcsfuse.git /tmp/update_benchmarks.YILFOC/gcsfuse
Cloning into '/tmp/update_benchmarks.YILFOC/gcsfuse'...
+ echo 'Repository cloned successfully.'
Repository cloned successfully.
+ pushd /tmp/update_benchmarks.YILFOC/gcsfuse
/tmp/update_benchmarks.YILFOC/gcsfuse ~/gcsfuse-tools/perf-benchmarking-for-releases
++ date +%s%N
+ BRANCH_TO_UPDATE_RESULTS_FROM=update-benchmarks-for-gcs-fuse-version-enable_read_manager_flag-timestamp-1750142678809608717
+ git checkout -b update-benchmarks-for-gcs-fuse-version-enable_read_manager_flag-timestamp-1750142678809608717
Switched to a new branch 'update-benchmarks-for-gcs-fuse-version-enable_read_manager_flag-timestamp-1750142678809608717'
+ GCSFUSE_VERSION_LINE_PREFIX='* GCSFuse version:'
+ GCSFUSE_VERSION_LINE_UPDATED='* GCSFuse version: enable_read_manager_flag'
+ BENCHMARKS_START_MARKER='<!-- Benchmarks start -->'
+ BENCHMARKS_END_MARKER='<!-- Benchmarks end -->'
+ update_benchmarks_based_on_markers /tmp/update_benchmarks.YILFOC/gcsfuse/docs/benchmarks.md /tmp/update_benchmarks.YILFOC/benchmarks.md '<!-- Benchmarks start -->' '<!-- Benchmarks end -->'
+ local target_file=/tmp/update_benchmarks.YILFOC/gcsfuse/docs/benchmarks.md
+ local source_file=/tmp/update_benchmarks.YILFOC/benchmarks.md
+ local 'start_marker=<!-- Benchmarks start -->'
+ local 'end_marker=<!-- Benchmarks end -->'
+ local temp_file
+ [[ ! -f /tmp/update_benchmarks.YILFOC/gcsfuse/docs/benchmarks.md ]]
+ [[ ! -s /tmp/update_benchmarks.YILFOC/gcsfuse/docs/benchmarks.md ]]
+ [[ ! -f /tmp/update_benchmarks.YILFOC/benchmarks.md ]]
+ local start_line_num
++ grep -n -m 1 '<!-- Benchmarks start -->' /tmp/update_benchmarks.YILFOC/gcsfuse/docs/benchmarks.md
++ cut -d: -f1
+ start_line_num=87
+ local end_line_num
+ [[ -n 87 ]]
++ tail -n +88 /tmp/update_benchmarks.YILFOC/gcsfuse/docs/benchmarks.md
++ grep -n -m 1 '<!-- Benchmarks end -->'
++ cut -d: -f1
+ end_line_num=87
+ [[ -n 87 ]]
+ end_line_num=174
+ [[ -z 87 ]]
+ [[ -z 174 ]]
+ [[ 87 -ge 174 ]]
++ mktemp
+ temp_file=/tmp/tmp.xIHuolURJM
+ [[ -z /tmp/tmp.xIHuolURJM ]]
+ [[ ! -f /tmp/tmp.xIHuolURJM ]]
+ trap 'rm -f "$temp_file"' EXIT
+ [[ 87 -gt 0 ]]
+ head -n 86 /tmp/update_benchmarks.YILFOC/gcsfuse/docs/benchmarks.md
+ echo '<!-- Benchmarks start -->'
+ echo ''
+ cat /tmp/update_benchmarks.YILFOC/benchmarks.md
+ echo ''
+ echo '<!-- Benchmarks end -->'
+ local total_lines
++ wc -l
+ total_lines=208
+ [[ 174 -lt 208 ]]
+ tail -n +175 /tmp/update_benchmarks.YILFOC/gcsfuse/docs/benchmarks.md
+ mv /tmp/tmp.xIHuolURJM /tmp/update_benchmarks.YILFOC/gcsfuse/docs/benchmarks.md
+ echo 'Content updated successfully in '\''/tmp/update_benchmarks.YILFOC/gcsfuse/docs/benchmarks.md'\''.'
Content updated successfully in '/tmp/update_benchmarks.YILFOC/gcsfuse/docs/benchmarks.md'.
+ trap - EXIT
+ return 0
+ sed -i '/^* GCSFuse version:/c* GCSFuse version: enable_read_manager_flag' docs/benchmarks.md
+ git add .
+ git commit -m 'update benchmark results for version enable_read_manager_flag'
[update-benchmarks-for-gcs-fuse-version-enable_read_manager_flag-timestamp-1750142678809608717 e3e601e65] update benchmark results for version enable_read_manager_flag
 1 file changed, 60 insertions(+), 59 deletions(-)
+ git push -u origin update-benchmarks-for-gcs-fuse-version-enable_read_manager_flag-timestamp-1750142678809608717
remote: 
remote: Create a pull request for 'update-benchmarks-for-gcs-fuse-version-enable_read_manager_flag-timestamp-1750142678809608717' on GitHub by visiting:        
remote:      https://github.com/GoogleCloudPlatform/gcsfuse/pull/new/update-benchmarks-for-gcs-fuse-version-enable_read_manager_flag-timestamp-1750142678809608717        
remote: 
remote: GitHub found 8 vulnerabilities on GoogleCloudPlatform/gcsfuse's default branch (5 high, 3 moderate). To find out more, visit:        
remote:      https://github.com/GoogleCloudPlatform/gcsfuse/security/dependabot        
remote: 
To https://github.com/GoogleCloudPlatform/gcsfuse.git
 * [new branch]          update-benchmarks-for-gcs-fuse-version-enable_read_manager_flag-timestamp-1750142678809608717 -> update-benchmarks-for-gcs-fuse-version-enable_read_manager_flag-timestamp-1750142678809608717
branch 'update-benchmarks-for-gcs-fuse-version-enable_read_manager_flag-timestamp-1750142678809608717' set up to track 'origin/update-benchmarks-for-gcs-fuse-version-enable_read_manager_flag-timestamp-1750142678809608717'.
+ popd
~/gcsfuse-tools/perf-benchmarking-for-releases
+ echo 'Results of benchmarks updated in branch: update-benchmarks-for-gcs-fuse-version-enable_read_manager_flag-timestamp-1750142678809608717'
Results of benchmarks updated in branch: update-benchmarks-for-gcs-fuse-version-enable_read_manager_flag-timestamp-1750142678809608717
+ echo 'Follow link to open the branch on github'
Follow link to open the branch on github
+ echo https://github.com/GoogleCloudPlatform/gcsfuse/tree/update-benchmarks-for-gcs-fuse-version-enable_read_manager_flag-timestamp-1750142678809608717
https://github.com/GoogleCloudPlatform/gcsfuse/tree/update-benchmarks-for-gcs-fuse-version-enable_read_manager_flag-timestamp-1750142678809608717
